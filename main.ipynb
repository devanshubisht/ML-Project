{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a44b7aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "class Model:  \n",
    "    \"\"\"\n",
    "    This class represents an AI model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "    def fillNanValues(self, image):\n",
    "        c, h, w = image.shape\n",
    "        nan_mask = np.isnan(image)\n",
    "        # Find indices of NaN values\n",
    "        nan_indices = np.where(nan_mask)\n",
    "        # Iterate through each NaN pixel and replace it with the mean of its neighbors\n",
    "        for idx in range(len(nan_indices[0])):\n",
    "            y, x = nan_indices[1][idx], nan_indices[2][idx]\n",
    "            # Extract the 8 neighboring pixels for each channel without wrapping around\n",
    "            for channel in range(c):\n",
    "                valid_neighbors = [\n",
    "                    image[channel, y2, x2]\n",
    "                    for y2 in range(max(0, y - 1), min(h, y + 2))\n",
    "                    for x2 in range(max(0, x - 1), min(w, x + 2))\n",
    "                    if (y2, x2) != (y, x)\n",
    "                ]\n",
    "                # Calculate the mean of the valid neighbors and replace the NaN value for each channel\n",
    "                image[channel, y, x] = np.nanmean(valid_neighbors)\n",
    "        return image\n",
    "    def oversample(self, images, labels):\n",
    "        minority_labels = [1, 2]\n",
    "        # Find the number of instances of label 0\n",
    "        num_instances_label_0 = np.sum(labels == 0)\n",
    "        for minority_label in minority_labels:\n",
    "            minority_indices = np.where(labels == minority_label)[0]\n",
    "            num_instances_to_add = num_instances_label_0 - len(minority_indices)\n",
    "            sampled_minority_indices = np.random.choice(minority_indices, size=num_instances_to_add, replace=True)\n",
    "            for idx in sampled_minority_indices:\n",
    "                # Assuming data is in the shape (C, H, W)\n",
    "                image_data = torch.tensor(images[idx])\n",
    "                if np.random.rand() < 0.3:\n",
    "                    image_data = torch.flip(image_data, dims=[2])\n",
    "                # Apply random vertical flip\n",
    "                if np.random.rand() < 0.3:\n",
    "                    image_data = torch.flip(image_data, dims=[1])\n",
    "                # Append the augmented data to the original dataset\n",
    "                images = np.concatenate([images, [image_data.numpy()]], axis=0)\n",
    "                labels = np.concatenate([labels, [minority_label]])\n",
    "        \n",
    "        return images, labels\n",
    "    \n",
    "    def preprocess(self, X, y= None):\n",
    "        if y is not None:\n",
    "            # Remove NaN labels\n",
    "            nan_mask = np.isnan(y)\n",
    "            labels = y[~nan_mask]\n",
    "            images = X[~nan_mask]\n",
    "            images[images < 0] = 0  # Set negative pixel values to 0\n",
    "            images[images > 255] = 255  # Set pixel values > 1 to 1\n",
    "            # Impute missing values\n",
    "            images = np.array([self.fillNanValues(img) for img in images])\n",
    "            # Oversample to handle imbalance through augmentation\n",
    "            images, labels = self.oversample(images, labels)\n",
    "            return (images, labels)\n",
    "        \n",
    "        else:\n",
    "            print(\"Preprocessing test data\")\n",
    "            X[X < 0] = 0  # Set negative pixel values to 0\n",
    "            X[X > 255] = 255\n",
    "            images = np.array([self.fillNanValues(img) for img in X])\n",
    "            return (images)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        images, labels = self.preprocess(X, y)\n",
    "        nan_count_dim0 = np.sum(np.isnan(images), axis=0)\n",
    "        images_train = torch.tensor(images, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "        train_dataset = TensorDataset(images_train, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        class CNN(nn.Module):\n",
    "            def __init__(self, num_classes, dropout_rate=0.2):\n",
    "                super(CNN, self).__init__()\n",
    "                self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "                self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "                self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "                \n",
    "                self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "                self.act = nn.LeakyReLU(negative_slope=0.02)\n",
    "                self.dropout = nn.Dropout2d(p=dropout_rate)\n",
    "                self.flatten = nn.Flatten()\n",
    "                self.fc1 = nn.Linear(128 * 2 * 2, num_classes)  # New linear layer\n",
    "                # self.relu = nn.ReLU()  # ReLU activation\n",
    "                # self.fc2 = nn.Linear(256, num_classes)\n",
    "            def forward(self, x):\n",
    "                x = self.dropout(self.pool(self.act(self.conv1(x))))\n",
    "                x = self.dropout(self.pool(self.act(self.conv2(x))))\n",
    "                x = self.dropout(self.pool(self.act(self.conv3(x))))\n",
    "                x = self.flatten(x)\n",
    "                # Apply the new linear layer with ReLU activation\n",
    "                x = self.fc1(x)\n",
    "                return x\n",
    "        # Instantiate the model\n",
    "        num_classes = 3  # Change this based on your dataset\n",
    "        self.model = CNN(num_classes)\n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        # Training the model\n",
    "        num_epochs = 30\n",
    "        for _ in range(num_epochs):\n",
    "            self.model.train()\n",
    "            running_loss = 0.0\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Preprocess the test data\n",
    "        X = self.preprocess(X)\n",
    "        \n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        # Make predictions using the trained neural network\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X_tensor)\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "        # Convert PyTorch tensor to numpy array\n",
    "        return predicted_labels.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02178d7",
   "metadata": {},
   "source": [
    "#### Local Evaluation\n",
    "\n",
    "You may test your solution locally by running the following code. Do note that the results may not reflect your performance in Coursemology. You should not be submitting the code below in Coursemology. The code here is meant only for you to do local testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4f4dd489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3064e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('data.npy', 'rb') as f:\n",
    "    data = np.load(f, allow_pickle=True).item()\n",
    "    X = data['image']\n",
    "    y = data['label']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
