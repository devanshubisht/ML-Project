{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "022cb4cd",
   "metadata": {},
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c14a2d8",
   "metadata": {},
   "source": [
    "##### Overview\n",
    "Used 3-Layer CNN to predict image datasets which were very random and had alot of missing and errornous values.\n",
    "\n",
    "##### 1. Descriptive Analysis\n",
    "\n",
    "A descriptive analysis was done by displaying the data and finding what were some of the values ranges in the data. This was important because it was important to identify that there were values outisde the possible [0,255] range.\n",
    "\n",
    "##### 2. Detection and Handling of Missing Values\n",
    "\n",
    "There were nan values in the image dataset and label dataset. Here are the following ways which I tackled it;\n",
    "\n",
    "1. Filter out the nan values in the label dataset and remove the corresponding rows in the image dataset\n",
    "\n",
    "2. When dealing with nan as vaues in the image data, these are the following steps I took:\n",
    "* I found which channel had nan values in each image and what were its corresponding height and weight.\n",
    "* I took the non nan average of the 8 possible pixels around it and inputed it as the value of the nan. This was the nearest neighhbour approach which I found online and was recommended to use. I used [ChatGPT](https://shareg.pt/1dbDLPF) to get the code for this.\n",
    "\n",
    "##### 3. Detection and Handling of Outliers\n",
    "\n",
    "1. I firstly identified what were the pixel values out of the [0,255] range. I accordingly scaled them down from <0 and >255 to 0 and 255 respectively.\n",
    "\n",
    "2. I then proceeded to test for the Zscore for pixel across the image but no outliers were found. This step was hence omitted from the final code.\n",
    "\n",
    "##### 4. Detection and Handling of Class Imbalance \n",
    "\n",
    "In response to the imbalanced class distribution with labels [0, 1, 2], where labels 1 and 2 were notably underrepresented, oversampling was implemented. This choice, as opposed to undersampling to avoid data leakage, aimed to bolster minority classes.\n",
    "\n",
    "During oversampling, data augmentation techniques such as horizontal and vertical flipping were applied to introduce both duplicated and similar images, particularly mimicking lower-numbered samples. This strategy enhances the model's ability to generalize without succumbing to overfitting.\n",
    "\n",
    "The combined approach of oversampling and careful data augmentation equips our model to navigate class imbalances effectively, fostering improved generalization and model robustness.\n",
    "\n",
    "##### 5. Understanding Relationship Between Variables\n",
    "\n",
    "It was difficult to establish the relationship between variables as there were only 3 variables which represented each row and column of an image. However, visualsation was done to see how the image looked like to see if there were any relationships.\n",
    "\n",
    "##### 6. Data Visualization\n",
    "\n",
    "I displayed the image in different formats which matplotlib provides to see if there were any relationships which could be established between the images. \n",
    "\n",
    "Given that initially the image had many pixels outisde the range of [0,255], I compared the differences between the unclean data and the cleaned data. However, little difference could be seen and the image seemed very scrambled.\n",
    "\n",
    "After attempting standardisation I attemped to visualise the image which made it much darker and only a few prominent pixels could be seen. However, no relationship and connection could be established.\n",
    "\n",
    "##### 7. General Preprocessing\n",
    "\n",
    "There was no need to change the data types of what was given. Other than clipping the data to 0 and 255, and interpolating the Nan values, I decided to keep the data in the float16 format to prevent any data leakage. \n",
    "\n",
    "I attmepted to standardise the datasets by dividing everything by 255 to make the range of values between 0 and 1. However, when tested on my neural network, it yielded a worse F1-score. This could be between due to the randomness of the image data, which made standrdising it lose some of its key features.\n",
    " \n",
    "##### 8. Feature Selection & Feature Engineering\n",
    "\n",
    "I did not carry out any feature selection or feature engineering or remove any data which was non a Nan or outlier.\n",
    "\n",
    "1. Image data often involves a large number of pixels, each serving as a feature and I did not want to have any possible data leakage.\n",
    "\n",
    "2. CNNs are designed to automatically learn hierarchical features from raw pixel data, making explicit feature selection less relevant.\n",
    "\n",
    "3. No linear dependency was observed among individual pixel values.\n",
    "\n",
    "4. Removing features could lead to information loss and hinder the model's ability to learn patterns.\n",
    "\n",
    "5. Avoiding feature selection mitigates the risk of data leakage.\n",
    "\n",
    "##### 10. Creating Models\n",
    "For my model, designed a covnet which took inspiration from ChatGPT, personal research and our past problem sets.\n",
    "\n",
    "$$\n",
    "\\text{Conv(32, (3,3))} \\rightarrow \\text{LReLU(0.02)} \\rightarrow \\text{AvgP((2,2))} \\rightarrow \\text{DO(0.2)} $$\n",
    "\n",
    "$$ \n",
    "\\rightarrow \\text{Conv(32, (3,3))}\\rightarrow \\text{LReLU(0.02)} \\rightarrow \\text{AvgP((2,2))} \\rightarrow \\text{DO(0.2)}  $$ \n",
    "\n",
    "$$  \\rightarrow \\text{Conv(32, (3,3))}  \\rightarrow \\text{LReLU(0.02)} \\rightarrow \\text{AvgP((2,2))} \\rightarrow \\text{DO(0.2)}  \\rightarrow \\text{Flat} \\rightarrow \\text{L(128*2*2, 3)}\n",
    "$$\n",
    "\n",
    "In my model there were mutiple considerations made.\n",
    "\n",
    "1. The usage of 3 Conv Layer. Previously, when I used 2 Conv Layers, the predicted values were not very consistent. This could be due to the complex nature of the data when related to the output classifications. \n",
    "\n",
    "2. The change of order of convolution. After doing [research](https://towardsdatascience.com/convolution-neural-networks-a-beginners-guide-implementing-a-mnist-hand-written-digit-8aa60330d022#:~:text=In%20practice%20RelU%20activation%20function,that%20output%20is%20max%20pooled.), I realised the best practive is to have layers in the order of Conv -> Activation -> Pool -> Dropout.\n",
    "\n",
    "3. The use of average pool over max pool was deliberate. This is because, due to the randomness of the dataset, I wanted to take the average to lower the possible variance which may be associated.\n",
    "\n",
    "4. [Initially](https://sharegpt.com/c/IrhruNK), I also tested with more Fully Connected Layers, but this increased the time taken for the model to train and to prevent overfitting, I removed it.\n",
    "\n",
    "5. Dropout for regularisation.\n",
    "\n",
    "Here were some of my refrences: \n",
    "1. ChatGPT. Gave the [general base](https://sharegpt.com/c/mE9AIfw).\n",
    "\n",
    "2. PS7. Inspired the use of LeakyRelu. Given that the I used 3 layers, and the dataset was random and had alot of noise, it was better to use LeakyRelu for more [dense networks](https://medium.com/mlearning-ai/activation-functions-relu-vs-leaky-relu-b8272dc0b1be).\n",
    "\n",
    "\n",
    "##### 11. Model Evaluation\n",
    "\n",
    "I used the train_test_split to evaluate the model.\n",
    "\n",
    "##### 12. Hyperparameters Search\n",
    "There were multiple areas in which I conducted hyperparameter testing.\n",
    "\n",
    "1. Amount of data to be agumented. I kept the probability low because I did not want to introduce even more randomness to the dataset.\n",
    "\n",
    "2. I also experimented with the Batch Size and the Learning Rate. The batch size was tested with 32, 64 and 128. This was done while also lowering the number of epochs so that the training wouldn't be too computationally intensive. The opportunity cost between batch size and epochs had to be weighed appropriately.\n",
    "\n",
    "3. Experimented with leaky relu gradient.\n",
    "\n",
    "##### Conclusion\n",
    "\n",
    "In overall these are the steps and decisions I took."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dcaf29",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27103374",
   "metadata": {},
   "source": [
    "# Workings (Not Graded)\n",
    "\n",
    "You will do your working below. Note that anything below this section will not be graded, but we might counter-check what you wrote in the report above with your workings to make sure that you actually did what you claimed to have done. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c6cd4",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "\n",
    "Here, we import some packages necessary to run this notebook. In addition, you may import other packages as well. Do note that when submitting your model, you may only use packages that are available in Coursemology (see `main.ipynb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "cded1ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from util import show_images, dict_train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748c35d7",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "The dataset `data/images.npy` is of size $(N, C, H, W)$, where $N$, $C$, $H$, and $W$ correspond to the number of data, image channels, image width, and image height, respectively.\n",
    "\n",
    "A code snippet that loads the data is provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09da291",
   "metadata": {},
   "source": [
    "### Load Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "6297e25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2911, 3, 16, 16)\n",
      "Shape: (2911,)\n"
     ]
    }
   ],
   "source": [
    "with open('data.npy', 'rb') as f:\n",
    "    data = np.load(f, allow_pickle=True).item()\n",
    "    images = data['image']\n",
    "    labels = data['label']\n",
    "    \n",
    "print('Shape:', images.shape)\n",
    "print('Shape:', labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 3.600e+01,        nan,  2.000e+01, ...,  1.900e+02,\n",
       "           1.700e+02,  1.620e+02],\n",
       "         [ 8.100e+01,  6.000e+01,  3.000e+01, ...,  1.900e+02,\n",
       "           1.800e+02,  1.770e+02],\n",
       "         [ 1.600e+02,  1.160e+02,  4.400e+01, ...,  1.850e+02,\n",
       "           1.980e+02,  2.040e+02],\n",
       "         ...,\n",
       "         [ 3.200e+01,  1.900e+01,  1.000e+00, ...,  1.720e+02,\n",
       "           1.910e+02,  1.960e+02],\n",
       "         [ 9.600e+01,  7.200e+01,  3.200e+01, ...,  2.260e+02,\n",
       "           2.210e+02,  2.100e+02],\n",
       "         [ 1.380e+02,  1.060e+02,  5.200e+01, ...,  2.550e+02,\n",
       "           2.390e+02,  2.200e+02]],\n",
       "\n",
       "        [[ 3.000e+00,  1.450e+02,  2.120e+02, ...,  8.000e+00,\n",
       "           8.400e+01,  2.250e+02],\n",
       "         [ 9.000e+01,  0.000e+00,  2.304e+03, ...,  4.800e+01,\n",
       "           1.250e+02,  2.500e+01],\n",
       "         [ 2.430e+02,  1.550e+02,  4.300e+01, ...,  5.200e+01,\n",
       "           1.890e+02,  2.300e+02],\n",
       "         ...,\n",
       "         [ 1.820e+02,  6.100e+01,  3.000e+00, ...,  6.900e+01,\n",
       "           1.910e+02, -9.872e+03],\n",
       "         [ 1.860e+02,  1.120e+02,  2.280e+02, ...,  8.100e+01,\n",
       "           2.370e+02,  5.600e+01],\n",
       "         [ 1.640e+02,  1.180e+02,  5.400e+01, ...,  5.900e+01,\n",
       "           1.200e+02,  2.330e+02]],\n",
       "\n",
       "        [[ 1.794e+01,  6.194e+01,  8.275e+01, ...,  1.948e+01,\n",
       "           4.303e+01,  8.675e+01],\n",
       "         [ 4.491e+01,  1.700e+01,  7.775e+01, ...,  3.188e+01,\n",
       "           5.575e+01,  2.475e+01],\n",
       "         [ 9.231e+01,  6.506e+01,  3.033e+01, ...,  3.312e+01,\n",
       "           7.556e+01,  8.831e+01],\n",
       "         ...,\n",
       "         [ 7.344e+01,  3.591e+01,  1.794e+01, ...,  3.838e+01,\n",
       "           7.619e+01,  2.195e+01],\n",
       "         [ 7.469e+01,  5.172e+01,  8.769e+01, ...,  4.212e+01,\n",
       "           9.050e+01,  3.438e+01],\n",
       "         [ 6.781e+01,  5.359e+01,  3.375e+01, ...,  3.528e+01,\n",
       "           5.419e+01,  8.925e+01]]],\n",
       "\n",
       "\n",
       "       [[[ 2.530e+02,  2.400e+02,  2.050e+02, ...,  2.410e+02,\n",
       "           8.100e+01,  0.000e+00],\n",
       "         [ 2.420e+02,  2.210e+02,  1.770e+02, ...,  2.160e+02,\n",
       "           6.800e+01,  0.000e+00],\n",
       "         [ 2.170e+02,  1.810e+02,  1.220e+02, ...,  1.750e+02,\n",
       "           5.300e+01,  0.000e+00],\n",
       "         ...,\n",
       "         [ 4.000e+00,  8.000e+00,  1.400e+01, ...,  1.820e+02,\n",
       "           2.020e+02,  2.080e+02],\n",
       "         [ 5.000e+01,  9.200e+01,  1.610e+02, ...,  1.750e+02,\n",
       "           1.730e+02,        nan],\n",
       "         [ 7.700e+01,  1.400e+02,  2.440e+02, ...,  1.660e+02,\n",
       "           1.530e+02,  1.460e+02]],\n",
       "\n",
       "        [[ 2.020e+02,  1.260e+02,  2.300e+01, ...,  2.420e+02,\n",
       "           2.060e+02,  1.000e+02],\n",
       "         [ 2.550e+02,  6.700e+01,  1.110e+02, ...,  1.040e+02,\n",
       "           1.970e+02,  9.000e+01],\n",
       "         [ 2.540e+02,  9.900e+01,  2.030e+02, ...,  2.370e+02,\n",
       "           5.400e+01,  1.430e+02],\n",
       "         ...,\n",
       "         [ 1.170e+02,  2.300e+02,  8.000e+00, ...,  8.900e+01,\n",
       "           1.770e+02,  4.000e+01],\n",
       "         [ 2.510e+02,  1.890e+02,  9.600e+01, ...,  5.900e+01,\n",
       "                 nan,  1.230e+02],\n",
       "         [ 1.650e+02,  1.770e+02,  0.000e+00, ...,  1.500e+01,\n",
       "           2.360e+02,  1.070e+02]],\n",
       "\n",
       "        [[ 7.962e+01,  5.606e+01,  2.412e+01, ...,  9.200e+01,\n",
       "           8.088e+01,  4.800e+01],\n",
       "         [ 2.940e+03,  3.778e+01,  5.141e+01, ...,  4.925e+01,\n",
       "           7.806e+01,  4.491e+01],\n",
       "         [ 9.575e+01,  4.769e+01,  7.994e+01, ...,  9.050e+01,\n",
       "           3.375e+01,  6.134e+01],\n",
       "         ...,\n",
       "         [ 5.328e+01,  8.831e+01,  3.254e+03, ...,  4.459e+01,\n",
       "           7.188e+01,  2.941e+01],\n",
       "         [ 9.481e+01,  7.556e+01,  4.675e+01, ...,  3.528e+01,\n",
       "           7.062e+01,  5.512e+01],\n",
       "         [ 6.812e+01,  7.188e+01,  1.700e+01, ...,  2.166e+01,\n",
       "           9.019e+01,  5.016e+01]]],\n",
       "\n",
       "\n",
       "       [[[ 2.370e+02,  1.480e+02,  3.000e+00, ...,  1.640e+02,\n",
       "           5.000e+01,  0.000e+00],\n",
       "         [ 1.880e+02,  1.530e+02,  9.400e+01, ...,  1.370e+02,\n",
       "           5.700e+01,  1.700e+01],\n",
       "         [ 1.020e+02,  1.560e+02,  2.400e+02, ...,  9.500e+01,\n",
       "           7.800e+01,  9.024e+03],\n",
       "         ...,\n",
       "         [ 2.400e+02, -2.244e+03,  2.200e+01, ...,  4.000e+01,\n",
       "           1.160e+02,  1.580e+02],\n",
       "         [ 1.630e+02,  1.400e+02,  1.020e+02, ...,  6.900e+01,\n",
       "           6.000e+01,  6.736e+03],\n",
       "         [ 1.170e+02,  1.270e+02,  1.470e+02, ...,  8.600e+01,\n",
       "           2.700e+01,  0.000e+00]],\n",
       "\n",
       "        [[ 1.260e+02,  1.440e+02,  1.610e+02, ...,  5.500e+01,\n",
       "           9.300e+01,  1.860e+02],\n",
       "         [ 1.100e+02,  1.210e+02,  1.920e+02, ...,  1.220e+02,\n",
       "           2.090e+02,  0.000e+00],\n",
       "         [ 2.220e+02,  2.000e+01,  1.960e+02, ...,  1.030e+02,\n",
       "           1.240e+02,  1.150e+02],\n",
       "         ...,\n",
       "         [ 2.500e+02,  1.060e+02,  2.200e+01, ...,  2.000e+01,\n",
       "           1.710e+02,  8.700e+01],\n",
       "         [ 6.700e+01,  2.280e+02,  1.850e+02, ...,  1.790e+02,\n",
       "           2.480e+02,  1.090e+02],\n",
       "         [ 4.100e+01,  0.000e+00,  8.900e+01, ...,  3.400e+01,\n",
       "           1.990e+02,  5.300e+01]],\n",
       "\n",
       "        [[ 5.606e+01,  6.162e+01,  6.694e+01, ...,  3.406e+01,\n",
       "           4.584e+01,  7.469e+01],\n",
       "         [ 5.109e+01,  5.450e+01,  7.650e+01, ...,  5.481e+01,\n",
       "           8.181e+01,  1.700e+01],\n",
       "         [ 8.581e+01,  2.320e+01,  7.775e+01, ...,  4.894e+01,\n",
       "           5.544e+01,  5.266e+01],\n",
       "         ...,\n",
       "         [ 9.450e+01,  4.988e+01,  2.381e+01, ...,  2.320e+01,\n",
       "           7.000e+01,  4.397e+01],\n",
       "         [ 3.778e+01,  8.769e+01,  7.438e+01, ...,  7.250e+01,\n",
       "           9.388e+01,  5.078e+01],\n",
       "         [ 2.970e+01,  1.700e+01,  4.459e+01, ...,  2.755e+01,\n",
       "           7.869e+01,  3.344e+01]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 4.400e+01,  3.800e+01,  2.700e+01, ...,  1.530e+02,\n",
       "           1.640e+02,  1.650e+02],\n",
       "         [ 5.400e+01,  6.600e+01,  8.500e+01, ...,  1.240e+02,\n",
       "           1.330e+02,  1.340e+02],\n",
       "         [ 7.400e+01,  1.120e+02,  1.780e+02, ...,  7.900e+01,\n",
       "           8.300e+01,  8.300e+01],\n",
       "         ...,\n",
       "         [ 1.190e+02,  7.600e+01,  6.000e+00, ...,  2.500e+01,\n",
       "           9.400e+01,  1.310e+02],\n",
       "         [ 7.200e+01,  5.400e+01,  3.200e+01, ...,  5.000e+01,\n",
       "           5.200e+01,  5.200e+01],\n",
       "         [ 4.700e+01,  4.200e+01,  4.600e+01, ...,  7.100e+01,\n",
       "           3.200e+01,  8.000e+00]],\n",
       "\n",
       "        [[ 9.500e+01,  1.680e+02,  1.080e+02, ...,  4.100e+01,\n",
       "           7.400e+01,  1.020e+02],\n",
       "         [ 4.100e+01,  1.710e+02,  1.090e+02, ...,  1.300e+02,\n",
       "           1.380e+02,  1.610e+02],\n",
       "         [ 2.010e+02,  2.450e+02,  1.580e+02, ...,  5.400e+01,\n",
       "           2.430e+02,  2.000e+02],\n",
       "         ...,\n",
       "         [ 1.000e+02,  2.350e+02,  2.050e+02, ...,  1.260e+02,\n",
       "           2.050e+02,  2.900e+01],\n",
       "         [ 2.180e+02,  8.500e+01,  2.300e+02, ...,  1.680e+02,\n",
       "           1.830e+02,  2.520e+02],\n",
       "         [ 2.170e+02,  1.500e+02,  2.420e+02, ...,  2.100e+01,\n",
       "           1.540e+02,  1.540e+02]],\n",
       "\n",
       "        [[ 4.644e+01,  6.906e+01,  5.047e+01, ...,  2.970e+01,\n",
       "           3.994e+01,  4.862e+01],\n",
       "         [ 2.970e+01,  7.000e+01,  5.078e+01, ...,  5.731e+01,\n",
       "           5.978e+01,  6.694e+01],\n",
       "         [ 7.931e+01,  9.294e+01,  6.600e+01, ...,  3.375e+01,\n",
       "           9.231e+01,  7.900e+01],\n",
       "         ...,\n",
       "         [ 4.800e+01,  8.988e+01,  8.056e+01, ...,  5.606e+01,\n",
       "           8.056e+01,  2.598e+01],\n",
       "         [ 8.456e+01,  4.334e+01,  8.831e+01, ...,  6.906e+01,\n",
       "           7.375e+01,  9.512e+01],\n",
       "         [ 8.425e+01,        nan,  9.200e+01, ...,  2.352e+01,\n",
       "           6.475e+01,  6.475e+01]]],\n",
       "\n",
       "\n",
       "       [[[ 1.290e+02,  1.610e+02,  2.170e+02, ...,  1.050e+02,\n",
       "           2.090e+02,  2.550e+02],\n",
       "         [ 1.320e+02,  1.520e+02,  1.890e+02, ...,  1.340e+02,\n",
       "           1.770e+02,  2.020e+02],\n",
       "         [ 1.340e+02,  1.300e+02,  1.320e+02, ...,  1.860e+02,\n",
       "           1.230e+02,  8.700e+01],\n",
       "         ...,\n",
       "         [ 1.640e+02,  1.130e+02,  2.200e+01, ...,  1.270e+02,\n",
       "           7.300e+01,  3.800e+01],\n",
       "         [ 1.360e+02,  1.440e+02,  1.570e+02, ...,  1.890e+02,\n",
       "           1.590e+02,  1.390e+02],\n",
       "         [ 1.150e+02,  1.590e+02,  2.330e+02, ...,  2.270e+02,\n",
       "           2.120e+02,  2.010e+02]],\n",
       "\n",
       "        [[ 2.160e+02,  1.230e+02,  3.100e+01, ...,  1.820e+02,\n",
       "           1.700e+01,  7.800e+01],\n",
       "         [ 6.000e+01,  9.600e+01,  7.800e+01, ...,  2.120e+02,\n",
       "           2.510e+02,  1.970e+02],\n",
       "         [ 1.100e+02,  1.840e+02,  2.010e+02, ...,  3.400e+01,\n",
       "           1.450e+02,  4.400e+01],\n",
       "         ...,\n",
       "         [ 9.800e+01,  1.000e+01,  1.460e+02, ...,  1.490e+02,\n",
       "           2.400e+01,  6.200e+01],\n",
       "         [ 8.800e+01,  2.500e+02,  2.220e+02, ...,  2.140e+02,\n",
       "           1.410e+02,        nan],\n",
       "         [ 1.500e+02,  4.800e+01,  6.400e+01, ...,  1.890e+02,\n",
       "           4.400e+01,  5.100e+01]],\n",
       "\n",
       "        [[ 8.394e+01,  5.512e+01,  2.661e+01, ...,  7.344e+01,\n",
       "           2.227e+01,  4.119e+01],\n",
       "         [ 3.559e+01,  4.675e+01,  4.119e+01, ...,  8.275e+01,\n",
       "           9.481e+01,  7.806e+01],\n",
       "         [ 1.999e+03,  7.406e+01,  7.931e+01, ...,  2.755e+01,\n",
       "           6.194e+01,  3.064e+01],\n",
       "         ...,\n",
       "         [ 4.738e+01,  2.009e+01,  6.225e+01, ...,  6.319e+01,\n",
       "           2.444e+01,  3.622e+01],\n",
       "         [ 4.428e+01,  9.450e+01,  8.581e+01, ...,  8.331e+01,\n",
       "           6.072e+01,  4.491e+01],\n",
       "         [ 6.350e+01,  3.188e+01,  3.684e+01, ...,  7.556e+01,\n",
       "           3.064e+01,  3.281e+01]]],\n",
       "\n",
       "\n",
       "       [[[ 6.400e+01,  1.100e+02,  1.830e+02, ...,  1.060e+02,\n",
       "           1.900e+02,  2.350e+02],\n",
       "         [ 1.050e+02,  1.310e+02,  1.730e+02, ...,  7.200e+01,\n",
       "           1.590e+02,  2.070e+02],\n",
       "         [ 1.690e+02,  1.610e+02,  1.490e+02, ...,  1.900e+01,\n",
       "          -6.300e+01,  1.510e+02],\n",
       "         ...,\n",
       "         [ 2.550e+02,  9.600e+03,  2.400e+01, ...,  1.710e+02,\n",
       "           1.830e+02,  1.840e+02],\n",
       "         [ 2.140e+02,  1.810e+02,  1.120e+02, ...,  9.200e+01,\n",
       "           1.150e+02,  1.280e+02],\n",
       "         [ 1.860e+02,  1.790e+02,  1.620e+02, ...,  4.400e+01,\n",
       "           7.700e+01,  9.800e+01]],\n",
       "\n",
       "        [[ 7.200e+01,  1.120e+02,  4.900e+01, ...,  1.330e+02,\n",
       "           3.900e+01,  1.820e+02],\n",
       "         [ 1.890e+02,  3.000e+00,  4.900e+01, ...,  2.530e+02,\n",
       "           1.770e+02,  6.000e+00],\n",
       "         [ 1.620e+02,  1.800e+02,  2.110e+02, ...,  1.990e+02,\n",
       "           1.620e+02,  1.110e+02],\n",
       "         ...,\n",
       "         [ 3.200e+01,  1.930e+02,  7.700e+01, ...,  1.290e+02,\n",
       "           2.040e+02,  1.310e+02],\n",
       "         [ 1.960e+02,  1.460e+02,  1.370e+02, ...,  4.900e+01,\n",
       "           7.800e+01,  4.900e+01],\n",
       "         [ 3.300e+01,  2.270e+02,  1.960e+02, ...,  1.790e+02,\n",
       "           1.460e+02,  2.270e+02]],\n",
       "\n",
       "        [[ 3.931e+01,  5.172e+01,  3.219e+01, ...,  5.822e+01,\n",
       "           2.909e+01,  7.344e+01],\n",
       "         [ 7.556e+01,  1.794e+01,  3.219e+01, ...,  9.544e+01,\n",
       "           7.188e+01,  1.886e+01],\n",
       "         [ 6.725e+01,  7.281e+01,  8.244e+01, ...,  7.869e+01,\n",
       "           6.725e+01,  5.141e+01],\n",
       "         ...,\n",
       "         [ 2.692e+01,  7.681e+01,  4.088e+01, ...,  5.700e+01,\n",
       "           8.025e+01,  5.762e+01],\n",
       "         [ 7.775e+01,  6.225e+01,  5.947e+01, ...,  3.219e+01,\n",
       "           4.119e+01,  3.219e+01],\n",
       "         [ 2.723e+01,  8.738e+01,  7.775e+01, ...,  7.250e+01,\n",
       "           6.225e+01,  8.738e+01]]]], dtype=float16)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe832b6",
   "metadata": {},
   "source": [
    "## Data Exploration & Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a464c",
   "metadata": {},
   "source": [
    "### 1. Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "3b1f62dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [nan  1.  0.  2.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def show_images1(images, n_row=3, n_col=2, figsize=[16, 16]):\n",
    "    _, axs = plt.subplots(n_row, n_col, figsize=figsize)\n",
    "    axs = axs.flatten()\n",
    "    for img, ax in zip(images, axs):\n",
    "        # Transpose image to put channels last and convert to float32\n",
    "        img = img.transpose((1, 2, 0))\n",
    "        ax.imshow(img.astype(np.uint8))\n",
    "    plt.show()\n",
    "\n",
    "# Display a subset of images\n",
    "show_images1(images[:6])\n",
    "print('Labels:', labels[:6])\n",
    "\n",
    "# Assuming images is of shape (N, C, H, W) and labels is of shape (N,)\n",
    "# Display the first 25 images\n",
    "# Index: 0, Height: 0, Column: 1\n",
    "# Index: 1, Height: 0, Column: 10\n",
    "# Index: 2, Height: 0, Column: 5\n",
    "# Index: 3, Height: 0, Column: 9\n",
    "# Index: 4, Height: 0, Column: 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'labels' is your array of labels\n",
    "unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "plt.bar(unique_labels, label_counts)\n",
    "\n",
    "plt.title('Label Distribution')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2. nan]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(labels)\n",
    "unique_values = np.unique(labels)\n",
    "print(unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask for NaN labels\n",
    "nan_mask = np.isnan(labels)\n",
    "\n",
    "# Remove rows with NaN labels\n",
    "labels = labels[~nan_mask]\n",
    "images = images[~nan_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2.], dtype=float16)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values = np.unique(labels)\n",
    "unique_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb61967",
   "metadata": {},
   "source": [
    "### 2. Detection and Handling of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "4bb9cdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2620, 3, 16, 16)\n",
      "Number of NaN values along dimension 0: [[[14 23 18 28 27 27 27 30 28 23 26 29 23 26 35 31]\n",
      "  [33 21 35 26 18 24 23 23 23 27 26 37 25 26 20 34]\n",
      "  [21 19 20 18 27 26 31 23 21 31 29 26 32 27 21 29]\n",
      "  [21 24 37 30 20 23 37 22 28 28 28 29 26 29 28 19]\n",
      "  [29 28 12 22 32 30 31 22 33 24 36 25 25 17 19 28]\n",
      "  [21 21 26 17 31 33 25 22 21 34 18 22 25 27 22 17]\n",
      "  [29 19 21 26 37 22 26 17 26 26 17 28 22 31 21 28]\n",
      "  [23 19 21 31 30 22 30 23 25 24 17 22 36 28 22 35]\n",
      "  [11 27 28 29 27 21 20 27 21 29 21 20 22 30 27 37]\n",
      "  [29 29 20 29 32 15 26 20 22 24 35 26 29 28 22 23]\n",
      "  [24 34 25 22 24 24 24 20 22 22 27 26 29 22 27 24]\n",
      "  [26 31 20 28 25 24 34 26 28 24 32 17 35 25 31 16]\n",
      "  [31 23 21 20 27 24 24 34 29 13 23 30 33 29 19 23]\n",
      "  [23 33 26 26 31 25 31 29 25 32 28 36 21 30 33 30]\n",
      "  [22 25 23 28 31 24 28 23 20 26 25 26 32 27 18 27]\n",
      "  [21 36 30 30 21 25 20 27 29 27 23 23 32 31 31 24]]\n",
      "\n",
      " [[26 32 22 25 30 27 28 24 22 29 38 35 25 25 21 20]\n",
      "  [18 23 30 22 20 20 27 33 33 19 24 21 19 29 34 20]\n",
      "  [23 29 27 32 23 28 18 31 23 23 20 20 32 29 25 26]\n",
      "  [22 25 24 29 19 16 26 31 28 21 29 19 27 19 23 25]\n",
      "  [29 32 24 17 22 23 28 26 26 25 25 26 30 22 21 27]\n",
      "  [21 27 27 29 20 27 20 34 21 20 31 23 19 21 16 36]\n",
      "  [32 23 22 27 26 21 24 24 20 32 33 27 19 26 25 32]\n",
      "  [21 26 25 16 27 28 26 32 23 24 25 25 25 27 19 20]\n",
      "  [26 21 27 30 21 27 28 21 16 32 28 16 26 34 23 24]\n",
      "  [31 26 32 27 30 29 30 30 28 26 26 27 22 25 21 22]\n",
      "  [31 24 23 18 24 28 21 20 36 21 26 26 41 28 38 24]\n",
      "  [19 26 25 26 22 30 23 19 29 24 18 23 34 32 28 20]\n",
      "  [34 27 26 34 34 17 35 21 31 26 31 32 20 16 20 22]\n",
      "  [33 12 25 30 30 27 20 32 34 28 29 29 21 23 41 29]\n",
      "  [25 24 33 22 29 27 27 33 27 22 31 23 29 25 25 18]\n",
      "  [29 30 33 21 24 21 25 21 18 29 26 22 27 25 25 32]]\n",
      "\n",
      " [[32 28 22 39 27 22 23 25 20 27 26 23 26 21 29 20]\n",
      "  [24 20 29 25 28 25 29 24 22 17 30 24 31 21 23 23]\n",
      "  [27 19 35 19 16 18 26 28 26 18 26 32 25 26 30 20]\n",
      "  [32 27 25 15 26 20 26 29 31 34 31 21 31 26 22 22]\n",
      "  [19 22 34 23 29 31 34 29 22 19 25 22 21 26 28 30]\n",
      "  [25 26 20 21 24 26 26 32 25 25 24 29 23 32 23 32]\n",
      "  [23 28 21 34 27 22 22 28 29 24 25 13 25 21 23 23]\n",
      "  [24 18 28 20 23 27 21 29 27 29 25 26 20 26 21 26]\n",
      "  [24 26 24 20 28 26 26 23 24 31 30 15 26 25 28 28]\n",
      "  [34 24 21 19 25 29 21 26 33 44 32 20 17 25 21 34]\n",
      "  [26 31 22 20 16 20 26 23 23 33 17 27 19 20 24 25]\n",
      "  [30 28 25 23 29 23 25 25 33 28 33 25 33 18 32 27]\n",
      "  [21 23 25 29 26 33 26 24 22 17 20 22 21 18 31 27]\n",
      "  [19 22 30 35 24 23 21 34 29 32 30 30 21 16 17 30]\n",
      "  [33 16 30 24 24 24 27 18 25 18 21 28 25 21 27 22]\n",
      "  [29 29 29 19 25 34 28 23 18 34 27 28 28 34 24 28]]]\n",
      "(3, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(images.shape)\n",
    "# Count NaN values along each dimension\n",
    "nan_count_dim0 = np.sum(np.isnan(images), axis=0)\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of NaN values along dimension 0:\", nan_count_dim0)\n",
    "print(nan_count_dim0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2911, 3, 16, 16)\n",
      "Shape: (2911,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('data.npy', 'rb') as f:\n",
    "    data = np.load(f, allow_pickle=True).item()\n",
    "    images = data['image']\n",
    "    labels = data['label']\n",
    "    \n",
    "print('Shape:', images.shape)\n",
    "print('Shape:', labels.shape)\n",
    "\n",
    "# Create a boolean mask for NaN labels\n",
    "nan_mask = np.isnan(labels)\n",
    "\n",
    "# Remove rows with NaN labels\n",
    "labels = labels[~nan_mask]\n",
    "images = images[~nan_mask]\n",
    "image_test = images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbor_interpolation(image):\n",
    "    c, h, w = image.shape\n",
    "\n",
    "    nan_mask = np.isnan(image)\n",
    "    # Find indices of NaN values\n",
    "    nan_indices = np.where(nan_mask)\n",
    "\n",
    "    # Iterate through each NaN pixel and replace it with the mean of its neighbors\n",
    "    for idx in range(len(nan_indices[0])):\n",
    "        y, x = nan_indices[1][idx], nan_indices[2][idx]\n",
    "\n",
    "        # Extract the 8 neighboring pixels for each channel without wrapping around\n",
    "        for channel in range(c):\n",
    "            valid_neighbors = [\n",
    "                image[channel, y2, x2]\n",
    "                for y2 in range(max(0, y - 1), min(h, y + 2))\n",
    "                for x2 in range(max(0, x - 1), min(w, x + 2))\n",
    "                if (y2, x2) != (y, x)\n",
    "            ]\n",
    "\n",
    "            # Calculate the mean of the valid neighbors and replace the NaN value for each channel\n",
    "            image[channel, y, x] = np.nanmean(valid_neighbors)\n",
    "\n",
    "    return image\n",
    "\n",
    "images_interpolated1 = np.array([interpolate_nan_pixels(img) for img in image_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 2.5300e+02,  2.4000e+02,  2.0500e+02, ...,  2.4100e+02,\n",
       "           8.1000e+01,  0.0000e+00],\n",
       "         [ 2.4200e+02,  2.2100e+02,  1.7700e+02, ...,  2.1600e+02,\n",
       "           6.8000e+01,  0.0000e+00],\n",
       "         [ 2.1700e+02,  1.8100e+02,  1.2200e+02, ...,  1.7500e+02,\n",
       "           5.3000e+01,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 4.0000e+00,  8.0000e+00,  1.4000e+01, ...,  1.8200e+02,\n",
       "           2.0200e+02,  2.0800e+02],\n",
       "         [ 5.0000e+01,  9.2000e+01,  1.6100e+02, ...,  1.7500e+02,\n",
       "           1.7300e+02,  1.7638e+02],\n",
       "         [ 7.7000e+01,  1.4000e+02,  2.4400e+02, ...,  1.6600e+02,\n",
       "           1.5300e+02,  1.4600e+02]],\n",
       "\n",
       "        [[ 2.0200e+02,  1.2600e+02,  2.3000e+01, ...,  2.4200e+02,\n",
       "           2.0600e+02,  1.0000e+02],\n",
       "         [ 2.5500e+02,  6.7000e+01,  1.1100e+02, ...,  1.0400e+02,\n",
       "           1.9700e+02,  9.0000e+01],\n",
       "         [ 2.5400e+02,  9.9000e+01,  2.0300e+02, ...,  2.3700e+02,\n",
       "           5.4000e+01,  1.4300e+02],\n",
       "         ...,\n",
       "         [ 1.1700e+02,  2.3000e+02,  8.0000e+00, ...,  8.9000e+01,\n",
       "           1.7700e+02,  4.0000e+01],\n",
       "         [ 2.5100e+02,  1.8900e+02,  9.6000e+01, ...,  5.9000e+01,\n",
       "           1.0575e+02,  1.2300e+02],\n",
       "         [ 1.6500e+02,  1.7700e+02,  0.0000e+00, ...,  1.5000e+01,\n",
       "           2.3600e+02,  1.0700e+02]],\n",
       "\n",
       "        [[ 7.9625e+01,  5.6062e+01,  2.4125e+01, ...,  9.2000e+01,\n",
       "           8.0875e+01,  4.8000e+01],\n",
       "         [ 2.9400e+03,  3.7781e+01,  5.1406e+01, ...,  4.9250e+01,\n",
       "           7.8062e+01,  4.4906e+01],\n",
       "         [ 9.5750e+01,  4.7688e+01,  7.9938e+01, ...,  9.0500e+01,\n",
       "           3.3750e+01,  6.1344e+01],\n",
       "         ...,\n",
       "         [ 5.3281e+01,  8.8312e+01,  3.2540e+03, ...,  4.4594e+01,\n",
       "           7.1875e+01,  2.9406e+01],\n",
       "         [ 9.4812e+01,  7.5562e+01,  4.6750e+01, ...,  3.5281e+01,\n",
       "           7.0625e+01,  5.5125e+01],\n",
       "         [ 6.8125e+01,  7.1875e+01,  1.7000e+01, ...,  2.1656e+01,\n",
       "           9.0188e+01,  5.0156e+01]]],\n",
       "\n",
       "\n",
       "       [[[ 2.3700e+02,  1.4800e+02,  3.0000e+00, ...,  1.6400e+02,\n",
       "           5.0000e+01,  0.0000e+00],\n",
       "         [ 1.8800e+02,  1.5300e+02,  9.4000e+01, ...,  1.3700e+02,\n",
       "           5.7000e+01,  1.7000e+01],\n",
       "         [ 1.0200e+02,  1.5600e+02,  2.4000e+02, ...,  9.5000e+01,\n",
       "           7.8000e+01,  9.0240e+03],\n",
       "         ...,\n",
       "         [ 2.4000e+02, -2.2440e+03,  2.2000e+01, ...,  4.0000e+01,\n",
       "           1.1600e+02,  1.5800e+02],\n",
       "         [ 1.6300e+02,  1.4000e+02,  1.0200e+02, ...,  6.9000e+01,\n",
       "           6.0000e+01,  6.7360e+03],\n",
       "         [ 1.1700e+02,  1.2700e+02,  1.4700e+02, ...,  8.6000e+01,\n",
       "           2.7000e+01,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.2600e+02,  1.4400e+02,  1.6100e+02, ...,  5.5000e+01,\n",
       "           9.3000e+01,  1.8600e+02],\n",
       "         [ 1.1000e+02,  1.2100e+02,  1.9200e+02, ...,  1.2200e+02,\n",
       "           2.0900e+02,  0.0000e+00],\n",
       "         [ 2.2200e+02,  2.0000e+01,  1.9600e+02, ...,  1.0300e+02,\n",
       "           1.2400e+02,  1.1500e+02],\n",
       "         ...,\n",
       "         [ 2.5000e+02,  1.0600e+02,  2.2000e+01, ...,  2.0000e+01,\n",
       "           1.7100e+02,  8.7000e+01],\n",
       "         [ 6.7000e+01,  2.2800e+02,  1.8500e+02, ...,  1.7900e+02,\n",
       "           2.4800e+02,  1.0900e+02],\n",
       "         [ 4.1000e+01,  0.0000e+00,  8.9000e+01, ...,  3.4000e+01,\n",
       "           1.9900e+02,  5.3000e+01]],\n",
       "\n",
       "        [[ 5.6062e+01,  6.1625e+01,  6.6938e+01, ...,  3.4062e+01,\n",
       "           4.5844e+01,  7.4688e+01],\n",
       "         [ 5.1094e+01,  5.4500e+01,  7.6500e+01, ...,  5.4812e+01,\n",
       "           8.1812e+01,  1.7000e+01],\n",
       "         [ 8.5812e+01,  2.3203e+01,  7.7750e+01, ...,  4.8938e+01,\n",
       "           5.5438e+01,  5.2656e+01],\n",
       "         ...,\n",
       "         [ 9.4500e+01,  4.9875e+01,  2.3812e+01, ...,  2.3203e+01,\n",
       "           7.0000e+01,  4.3969e+01],\n",
       "         [ 3.7781e+01,  8.7688e+01,  7.4375e+01, ...,  7.2500e+01,\n",
       "           9.3875e+01,  5.0781e+01],\n",
       "         [ 2.9703e+01,  1.7000e+01,  4.4594e+01, ...,  2.7547e+01,\n",
       "           7.8688e+01,  3.3438e+01]]],\n",
       "\n",
       "\n",
       "       [[[ 2.3700e+02,  2.0800e+02,  1.5100e+02, ...,  2.1800e+02,\n",
       "           6.7000e+01,  0.0000e+00],\n",
       "         [ 2.4000e+02,  2.0400e+02,  1.3400e+02, ...,  1.9300e+02,\n",
       "           7.6000e+01,  1.9000e+01],\n",
       "         [ 2.3500e+02,  1.8600e+02,  9.9000e+01, ...,  1.4600e+02,\n",
       "           9.2000e+01,  6.2000e+01],\n",
       "         ...,\n",
       "         [ 2.5500e+02,  1.8200e+02,  3.6000e+01, ...,  9.6000e+01,\n",
       "           1.4100e+02,  1.6300e+02],\n",
       "         [ 2.5500e+02,  1.9500e+02,  8.4000e+01, ...,  1.7000e+02,\n",
       "           1.4100e+02,  1.2000e+02],\n",
       "         [ 2.5400e+02,  1.9900e+02,  1.1100e+02, ...,  2.1000e+02,\n",
       "           1.3800e+02,  9.3000e+01]],\n",
       "\n",
       "        [[ 9.7000e+01,  1.2000e+01,  4.6000e+01, ...,  9.5000e+01,\n",
       "           1.1100e+02,  4.7000e+01],\n",
       "         [ 1.6000e+01,  1.7300e+02,  7.9000e+01, ...,  5.0000e+01,\n",
       "           2.2700e+02,  1.2500e+02],\n",
       "         [ 1.6100e+02,  1.3700e+02,  7.0000e+00, ...,  1.6500e+02,\n",
       "           0.0000e+00,  1.8000e+01],\n",
       "         ...,\n",
       "         [ 1.1000e+02,  4.9000e+01,  1.2100e+02, ...,  1.2500e+02,\n",
       "           7.9000e+01,  2.0700e+02],\n",
       "         [ 2.1900e+02,  1.3100e+02,  1.4200e+02, ...,  9.3000e+01,\n",
       "           4.3000e+01,  7.9000e+01],\n",
       "         [ 1.6500e+02,  1.1800e+02,  4.0000e+01, ...,  1.2000e+02,\n",
       "           4.3000e+01,  2.1400e+02]],\n",
       "\n",
       "        [[ 4.7062e+01,  2.0719e+01,  3.1266e+01, ...,  4.6438e+01,\n",
       "           5.1406e+01,  3.1562e+01],\n",
       "         [ 2.1953e+01,  7.0625e+01,  4.1500e+01, ...,  3.2500e+01,\n",
       "           8.7375e+01,  5.5750e+01],\n",
       "         [ 6.6938e+01,  5.9469e+01,  1.9172e+01, ...,  6.8125e+01,\n",
       "           1.7000e+01,  2.2578e+01],\n",
       "         ...,\n",
       "         [ 5.1094e+01,  3.2188e+01,  5.4500e+01, ...,  5.5750e+01,\n",
       "           4.1500e+01,  8.1188e+01],\n",
       "         [ 8.4875e+01,  5.7625e+01,  6.1031e+01, ...,  9.3875e+01,\n",
       "           3.0328e+01,  4.1500e+01],\n",
       "         [ 6.8125e+01,  5.3594e+01,  2.9406e+01, ...,  5.4188e+01,\n",
       "           3.0328e+01,  8.3312e+01]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 4.4000e+01,  3.8000e+01,  2.7000e+01, ...,  1.5300e+02,\n",
       "           1.6400e+02,  1.6500e+02],\n",
       "         [ 5.4000e+01,  6.6000e+01,  8.5000e+01, ...,  1.2400e+02,\n",
       "           1.3300e+02,  1.3400e+02],\n",
       "         [ 7.4000e+01,  1.1200e+02,  1.7800e+02, ...,  7.9000e+01,\n",
       "           8.3000e+01,  8.3000e+01],\n",
       "         ...,\n",
       "         [ 1.1900e+02,  7.6000e+01,  6.0000e+00, ...,  2.5000e+01,\n",
       "           9.4000e+01,  1.3100e+02],\n",
       "         [ 7.2000e+01,  5.4000e+01,  3.2000e+01, ...,  5.0000e+01,\n",
       "           5.2000e+01,  5.2000e+01],\n",
       "         [ 4.7000e+01,  4.2000e+01,  4.6000e+01, ...,  7.1000e+01,\n",
       "           3.2000e+01,  8.0000e+00]],\n",
       "\n",
       "        [[ 9.5000e+01,  1.6800e+02,  1.0800e+02, ...,  4.1000e+01,\n",
       "           7.4000e+01,  1.0200e+02],\n",
       "         [ 4.1000e+01,  1.7100e+02,  1.0900e+02, ...,  1.3000e+02,\n",
       "           1.3800e+02,  1.6100e+02],\n",
       "         [ 2.0100e+02,  2.4500e+02,  1.5800e+02, ...,  5.4000e+01,\n",
       "           2.4300e+02,  2.0000e+02],\n",
       "         ...,\n",
       "         [ 1.0000e+02,  2.3500e+02,  2.0500e+02, ...,  1.2600e+02,\n",
       "           2.0500e+02,  2.9000e+01],\n",
       "         [ 2.1800e+02,  8.5000e+01,  2.3000e+02, ...,  1.6800e+02,\n",
       "           1.8300e+02,  2.5200e+02],\n",
       "         [ 2.1700e+02,  1.5000e+02,  2.4200e+02, ...,  2.1000e+01,\n",
       "           1.5400e+02,  1.5400e+02]],\n",
       "\n",
       "        [[ 4.6438e+01,  6.9062e+01,  5.0469e+01, ...,  2.9703e+01,\n",
       "           3.9938e+01,  4.8625e+01],\n",
       "         [ 2.9703e+01,  7.0000e+01,  5.0781e+01, ...,  5.7312e+01,\n",
       "           5.9781e+01,  6.6938e+01],\n",
       "         [ 7.9312e+01,  9.2938e+01,  6.6000e+01, ...,  3.3750e+01,\n",
       "           9.2312e+01,  7.9000e+01],\n",
       "         ...,\n",
       "         [ 4.8000e+01,  8.9875e+01,  8.0562e+01, ...,  5.6062e+01,\n",
       "           8.0562e+01,  2.5984e+01],\n",
       "         [ 8.4562e+01,  4.3344e+01,  8.8312e+01, ...,  6.9062e+01,\n",
       "           7.3750e+01,  9.5125e+01],\n",
       "         [ 8.4250e+01,  7.8500e+01,  9.2000e+01, ...,  2.3516e+01,\n",
       "           6.4750e+01,  6.4750e+01]]],\n",
       "\n",
       "\n",
       "       [[[ 1.2900e+02,  1.6100e+02,  2.1700e+02, ...,  1.0500e+02,\n",
       "           2.0900e+02,  2.5500e+02],\n",
       "         [ 1.3200e+02,  1.5200e+02,  1.8900e+02, ...,  1.3400e+02,\n",
       "           1.7700e+02,  2.0200e+02],\n",
       "         [ 1.3400e+02,  1.3000e+02,  1.3200e+02, ...,  1.8600e+02,\n",
       "           1.2300e+02,  8.7000e+01],\n",
       "         ...,\n",
       "         [ 1.6400e+02,  1.1300e+02,  2.2000e+01, ...,  1.2700e+02,\n",
       "           7.3000e+01,  3.8000e+01],\n",
       "         [ 1.3600e+02,  1.4400e+02,  1.5700e+02, ...,  1.8900e+02,\n",
       "           1.5900e+02,  1.3900e+02],\n",
       "         [ 1.1500e+02,  1.5900e+02,  2.3300e+02, ...,  2.2700e+02,\n",
       "           2.1200e+02,  2.0100e+02]],\n",
       "\n",
       "        [[ 2.1600e+02,  1.2300e+02,  3.1000e+01, ...,  1.8200e+02,\n",
       "           1.7000e+01,  7.8000e+01],\n",
       "         [ 6.0000e+01,  9.6000e+01,  7.8000e+01, ...,  2.1200e+02,\n",
       "           2.5100e+02,  1.9700e+02],\n",
       "         [ 1.1000e+02,  1.8400e+02,  2.0100e+02, ...,  3.4000e+01,\n",
       "           1.4500e+02,  4.4000e+01],\n",
       "         ...,\n",
       "         [ 9.8000e+01,  1.0000e+01,  1.4600e+02, ...,  1.4900e+02,\n",
       "           2.4000e+01,  6.2000e+01],\n",
       "         [ 8.8000e+01,  2.5000e+02,  2.2200e+02, ...,  2.1400e+02,\n",
       "           1.4100e+02,  6.4375e+01],\n",
       "         [ 1.5000e+02,  4.8000e+01,  6.4000e+01, ...,  1.8900e+02,\n",
       "           4.4000e+01,  5.1000e+01]],\n",
       "\n",
       "        [[ 8.3938e+01,  5.5125e+01,  2.6609e+01, ...,  7.3438e+01,\n",
       "           2.2266e+01,  4.1188e+01],\n",
       "         [ 3.5594e+01,  4.6750e+01,  4.1188e+01, ...,  8.2750e+01,\n",
       "           9.4812e+01,  7.8062e+01],\n",
       "         [ 1.9990e+03,  7.4062e+01,  7.9312e+01, ...,  2.7547e+01,\n",
       "           6.1938e+01,  3.0641e+01],\n",
       "         ...,\n",
       "         [ 4.7375e+01,  2.0094e+01,  6.2250e+01, ...,  6.3188e+01,\n",
       "           2.4438e+01,  3.6219e+01],\n",
       "         [ 4.4281e+01,  9.4500e+01,  8.5812e+01, ...,  8.3312e+01,\n",
       "           6.0719e+01,  4.4906e+01],\n",
       "         [ 6.3500e+01,  3.1875e+01,  3.6844e+01, ...,  7.5562e+01,\n",
       "           3.0641e+01,  3.2812e+01]]],\n",
       "\n",
       "\n",
       "       [[[ 6.4000e+01,  1.1000e+02,  1.8300e+02, ...,  1.0600e+02,\n",
       "           1.9000e+02,  2.3500e+02],\n",
       "         [ 1.0500e+02,  1.3100e+02,  1.7300e+02, ...,  7.2000e+01,\n",
       "           1.5900e+02,  2.0700e+02],\n",
       "         [ 1.6900e+02,  1.6100e+02,  1.4900e+02, ...,  1.9000e+01,\n",
       "          -6.3000e+01,  1.5100e+02],\n",
       "         ...,\n",
       "         [ 2.5500e+02,  9.6000e+03,  2.4000e+01, ...,  1.7100e+02,\n",
       "           1.8300e+02,  1.8400e+02],\n",
       "         [ 2.1400e+02,  1.8100e+02,  1.1200e+02, ...,  9.2000e+01,\n",
       "           1.1500e+02,  1.2800e+02],\n",
       "         [ 1.8600e+02,  1.7900e+02,  1.6200e+02, ...,  4.4000e+01,\n",
       "           7.7000e+01,  9.8000e+01]],\n",
       "\n",
       "        [[ 7.2000e+01,  1.1200e+02,  4.9000e+01, ...,  1.3300e+02,\n",
       "           3.9000e+01,  1.8200e+02],\n",
       "         [ 1.8900e+02,  3.0000e+00,  4.9000e+01, ...,  2.5300e+02,\n",
       "           1.7700e+02,  6.0000e+00],\n",
       "         [ 1.6200e+02,  1.8000e+02,  2.1100e+02, ...,  1.9900e+02,\n",
       "           1.6200e+02,  1.1100e+02],\n",
       "         ...,\n",
       "         [ 3.2000e+01,  1.9300e+02,  7.7000e+01, ...,  1.2900e+02,\n",
       "           2.0400e+02,  1.3100e+02],\n",
       "         [ 1.9600e+02,  1.4600e+02,  1.3700e+02, ...,  4.9000e+01,\n",
       "           7.8000e+01,  4.9000e+01],\n",
       "         [ 3.3000e+01,  2.2700e+02,  1.9600e+02, ...,  1.7900e+02,\n",
       "           1.4600e+02,  2.2700e+02]],\n",
       "\n",
       "        [[ 3.9312e+01,  5.1719e+01,  3.2188e+01, ...,  5.8219e+01,\n",
       "           2.9094e+01,  7.3438e+01],\n",
       "         [ 7.5562e+01,  1.7938e+01,  3.2188e+01, ...,  9.5438e+01,\n",
       "           7.1875e+01,  1.8859e+01],\n",
       "         [ 6.7250e+01,  7.2812e+01,  8.2438e+01, ...,  7.8688e+01,\n",
       "           6.7250e+01,  5.1406e+01],\n",
       "         ...,\n",
       "         [ 2.6922e+01,  7.6812e+01,  4.0875e+01, ...,  5.7000e+01,\n",
       "           8.0250e+01,  5.7625e+01],\n",
       "         [ 7.7750e+01,  6.2250e+01,  5.9469e+01, ...,  3.2188e+01,\n",
       "           4.1188e+01,  3.2188e+01],\n",
       "         [ 2.7234e+01,  8.7375e+01,  7.7750e+01, ...,  7.2500e+01,\n",
       "           6.2250e+01,  8.7375e+01]]]], dtype=float16)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "are_equal = np.array_equal(images_interpolated, images_interpolated1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(are_equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adcb9cd",
   "metadata": {},
   "source": [
    "### 3. Detection and Handling of Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ed1c17a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2620, 768)\n",
      "[[[[ 2.5300e+02  2.4000e+02  2.0500e+02 ...  2.4100e+02  8.1000e+01\n",
      "     0.0000e+00]\n",
      "   [ 2.4200e+02  2.2100e+02  1.7700e+02 ...  2.1600e+02  6.8000e+01\n",
      "     0.0000e+00]\n",
      "   [ 2.1700e+02  1.8100e+02  1.2200e+02 ...  1.7500e+02  5.3000e+01\n",
      "     0.0000e+00]\n",
      "   ...\n",
      "   [ 4.0000e+00  8.0000e+00  1.4000e+01 ...  1.8200e+02  2.0200e+02\n",
      "     2.0800e+02]\n",
      "   [ 5.0000e+01  9.2000e+01  1.6100e+02 ...  1.7500e+02  1.7300e+02\n",
      "     1.7638e+02]\n",
      "   [ 7.7000e+01  1.4000e+02  2.4400e+02 ...  1.6600e+02  1.5300e+02\n",
      "     1.4600e+02]]\n",
      "\n",
      "  [[ 2.0200e+02  1.2600e+02  2.3000e+01 ...  2.4200e+02  2.0600e+02\n",
      "     1.0000e+02]\n",
      "   [ 2.5500e+02  6.7000e+01  1.1100e+02 ...  1.0400e+02  1.9700e+02\n",
      "     9.0000e+01]\n",
      "   [ 2.5400e+02  9.9000e+01  2.0300e+02 ...  2.3700e+02  5.4000e+01\n",
      "     1.4300e+02]\n",
      "   ...\n",
      "   [ 1.1700e+02  2.3000e+02  8.0000e+00 ...  8.9000e+01  1.7700e+02\n",
      "     4.0000e+01]\n",
      "   [ 2.5100e+02  1.8900e+02  9.6000e+01 ...  5.9000e+01  1.0575e+02\n",
      "     1.2300e+02]\n",
      "   [ 1.6500e+02  1.7700e+02  0.0000e+00 ...  1.5000e+01  2.3600e+02\n",
      "     1.0700e+02]]\n",
      "\n",
      "  [[ 7.9625e+01  5.6062e+01  2.4125e+01 ...  9.2000e+01  8.0875e+01\n",
      "     4.8000e+01]\n",
      "   [ 2.9400e+03  3.7781e+01  5.1406e+01 ...  4.9250e+01  7.8062e+01\n",
      "     4.4906e+01]\n",
      "   [ 9.5750e+01  4.7688e+01  7.9938e+01 ...  9.0500e+01  3.3750e+01\n",
      "     6.1344e+01]\n",
      "   ...\n",
      "   [ 5.3281e+01  8.8312e+01  3.2540e+03 ...  4.4594e+01  7.1875e+01\n",
      "     2.9406e+01]\n",
      "   [ 9.4812e+01  7.5562e+01  4.6750e+01 ...  3.5281e+01  7.0625e+01\n",
      "     5.5125e+01]\n",
      "   [ 6.8125e+01  7.1875e+01  1.7000e+01 ...  2.1656e+01  9.0188e+01\n",
      "     5.0156e+01]]]\n",
      "\n",
      "\n",
      " [[[ 2.3700e+02  1.4800e+02  3.0000e+00 ...  1.6400e+02  5.0000e+01\n",
      "     0.0000e+00]\n",
      "   [ 1.8800e+02  1.5300e+02  9.4000e+01 ...  1.3700e+02  5.7000e+01\n",
      "     1.7000e+01]\n",
      "   [ 1.0200e+02  1.5600e+02  2.4000e+02 ...  9.5000e+01  7.8000e+01\n",
      "     9.0240e+03]\n",
      "   ...\n",
      "   [ 2.4000e+02 -2.2440e+03  2.2000e+01 ...  4.0000e+01  1.1600e+02\n",
      "     1.5800e+02]\n",
      "   [ 1.6300e+02  1.4000e+02  1.0200e+02 ...  6.9000e+01  6.0000e+01\n",
      "     6.7360e+03]\n",
      "   [ 1.1700e+02  1.2700e+02  1.4700e+02 ...  8.6000e+01  2.7000e+01\n",
      "     0.0000e+00]]\n",
      "\n",
      "  [[ 1.2600e+02  1.4400e+02  1.6100e+02 ...  5.5000e+01  9.3000e+01\n",
      "     1.8600e+02]\n",
      "   [ 1.1000e+02  1.2100e+02  1.9200e+02 ...  1.2200e+02  2.0900e+02\n",
      "     0.0000e+00]\n",
      "   [ 2.2200e+02  2.0000e+01  1.9600e+02 ...  1.0300e+02  1.2400e+02\n",
      "     1.1500e+02]\n",
      "   ...\n",
      "   [ 2.5000e+02  1.0600e+02  2.2000e+01 ...  2.0000e+01  1.7100e+02\n",
      "     8.7000e+01]\n",
      "   [ 6.7000e+01  2.2800e+02  1.8500e+02 ...  1.7900e+02  2.4800e+02\n",
      "     1.0900e+02]\n",
      "   [ 4.1000e+01  0.0000e+00  8.9000e+01 ...  3.4000e+01  1.9900e+02\n",
      "     5.3000e+01]]\n",
      "\n",
      "  [[ 5.6062e+01  6.1625e+01  6.6938e+01 ...  3.4062e+01  4.5844e+01\n",
      "     7.4688e+01]\n",
      "   [ 5.1094e+01  5.4500e+01  7.6500e+01 ...  5.4812e+01  8.1812e+01\n",
      "     1.7000e+01]\n",
      "   [ 8.5812e+01  2.3203e+01  7.7750e+01 ...  4.8938e+01  5.5438e+01\n",
      "     5.2656e+01]\n",
      "   ...\n",
      "   [ 9.4500e+01  4.9875e+01  2.3812e+01 ...  2.3203e+01  7.0000e+01\n",
      "     4.3969e+01]\n",
      "   [ 3.7781e+01  8.7688e+01  7.4375e+01 ...  7.2500e+01  9.3875e+01\n",
      "     5.0781e+01]\n",
      "   [ 2.9703e+01  1.7000e+01  4.4594e+01 ...  2.7547e+01  7.8688e+01\n",
      "     3.3438e+01]]]\n",
      "\n",
      "\n",
      " [[[ 2.3700e+02  2.0800e+02  1.5100e+02 ...  2.1800e+02  6.7000e+01\n",
      "     0.0000e+00]\n",
      "   [ 2.4000e+02  2.0400e+02  1.3400e+02 ...  1.9300e+02  7.6000e+01\n",
      "     1.9000e+01]\n",
      "   [ 2.3500e+02  1.8600e+02  9.9000e+01 ...  1.4600e+02  9.2000e+01\n",
      "     6.2000e+01]\n",
      "   ...\n",
      "   [ 2.5500e+02  1.8200e+02  3.6000e+01 ...  9.6000e+01  1.4100e+02\n",
      "     1.6300e+02]\n",
      "   [ 2.5500e+02  1.9500e+02  8.4000e+01 ...  1.7000e+02  1.4100e+02\n",
      "     1.2000e+02]\n",
      "   [ 2.5400e+02  1.9900e+02  1.1100e+02 ...  2.1000e+02  1.3800e+02\n",
      "     9.3000e+01]]\n",
      "\n",
      "  [[ 9.7000e+01  1.2000e+01  4.6000e+01 ...  9.5000e+01  1.1100e+02\n",
      "     4.7000e+01]\n",
      "   [ 1.6000e+01  1.7300e+02  7.9000e+01 ...  5.0000e+01  2.2700e+02\n",
      "     1.2500e+02]\n",
      "   [ 1.6100e+02  1.3700e+02  7.0000e+00 ...  1.6500e+02  0.0000e+00\n",
      "     1.8000e+01]\n",
      "   ...\n",
      "   [ 1.1000e+02  4.9000e+01  1.2100e+02 ...  1.2500e+02  7.9000e+01\n",
      "     2.0700e+02]\n",
      "   [ 2.1900e+02  1.3100e+02  1.4200e+02 ...  9.3000e+01  4.3000e+01\n",
      "     7.9000e+01]\n",
      "   [ 1.6500e+02  1.1800e+02  4.0000e+01 ...  1.2000e+02  4.3000e+01\n",
      "     2.1400e+02]]\n",
      "\n",
      "  [[ 4.7062e+01  2.0719e+01  3.1266e+01 ...  4.6438e+01  5.1406e+01\n",
      "     3.1562e+01]\n",
      "   [ 2.1953e+01  7.0625e+01  4.1500e+01 ...  3.2500e+01  8.7375e+01\n",
      "     5.5750e+01]\n",
      "   [ 6.6938e+01  5.9469e+01  1.9172e+01 ...  6.8125e+01  1.7000e+01\n",
      "     2.2578e+01]\n",
      "   ...\n",
      "   [ 5.1094e+01  3.2188e+01  5.4500e+01 ...  5.5750e+01  4.1500e+01\n",
      "     8.1188e+01]\n",
      "   [ 8.4875e+01  5.7625e+01  6.1031e+01 ...  9.3875e+01  3.0328e+01\n",
      "     4.1500e+01]\n",
      "   [ 6.8125e+01  5.3594e+01  2.9406e+01 ...  5.4188e+01  3.0328e+01\n",
      "     8.3312e+01]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 4.4000e+01  3.8000e+01  2.7000e+01 ...  1.5300e+02  1.6400e+02\n",
      "     1.6500e+02]\n",
      "   [ 5.4000e+01  6.6000e+01  8.5000e+01 ...  1.2400e+02  1.3300e+02\n",
      "     1.3400e+02]\n",
      "   [ 7.4000e+01  1.1200e+02  1.7800e+02 ...  7.9000e+01  8.3000e+01\n",
      "     8.3000e+01]\n",
      "   ...\n",
      "   [ 1.1900e+02  7.6000e+01  6.0000e+00 ...  2.5000e+01  9.4000e+01\n",
      "     1.3100e+02]\n",
      "   [ 7.2000e+01  5.4000e+01  3.2000e+01 ...  5.0000e+01  5.2000e+01\n",
      "     5.2000e+01]\n",
      "   [ 4.7000e+01  4.2000e+01  4.6000e+01 ...  7.1000e+01  3.2000e+01\n",
      "     8.0000e+00]]\n",
      "\n",
      "  [[ 9.5000e+01  1.6800e+02  1.0800e+02 ...  4.1000e+01  7.4000e+01\n",
      "     1.0200e+02]\n",
      "   [ 4.1000e+01  1.7100e+02  1.0900e+02 ...  1.3000e+02  1.3800e+02\n",
      "     1.6100e+02]\n",
      "   [ 2.0100e+02  2.4500e+02  1.5800e+02 ...  5.4000e+01  2.4300e+02\n",
      "     2.0000e+02]\n",
      "   ...\n",
      "   [ 1.0000e+02  2.3500e+02  2.0500e+02 ...  1.2600e+02  2.0500e+02\n",
      "     2.9000e+01]\n",
      "   [ 2.1800e+02  8.5000e+01  2.3000e+02 ...  1.6800e+02  1.8300e+02\n",
      "     2.5200e+02]\n",
      "   [ 2.1700e+02  1.5000e+02  2.4200e+02 ...  2.1000e+01  1.5400e+02\n",
      "     1.5400e+02]]\n",
      "\n",
      "  [[ 4.6438e+01  6.9062e+01  5.0469e+01 ...  2.9703e+01  3.9938e+01\n",
      "     4.8625e+01]\n",
      "   [ 2.9703e+01  7.0000e+01  5.0781e+01 ...  5.7312e+01  5.9781e+01\n",
      "     6.6938e+01]\n",
      "   [ 7.9312e+01  9.2938e+01  6.6000e+01 ...  3.3750e+01  9.2312e+01\n",
      "     7.9000e+01]\n",
      "   ...\n",
      "   [ 4.8000e+01  8.9875e+01  8.0562e+01 ...  5.6062e+01  8.0562e+01\n",
      "     2.5984e+01]\n",
      "   [ 8.4562e+01  4.3344e+01  8.8312e+01 ...  6.9062e+01  7.3750e+01\n",
      "     9.5125e+01]\n",
      "   [ 8.4250e+01  7.8500e+01  9.2000e+01 ...  2.3516e+01  6.4750e+01\n",
      "     6.4750e+01]]]\n",
      "\n",
      "\n",
      " [[[ 1.2900e+02  1.6100e+02  2.1700e+02 ...  1.0500e+02  2.0900e+02\n",
      "     2.5500e+02]\n",
      "   [ 1.3200e+02  1.5200e+02  1.8900e+02 ...  1.3400e+02  1.7700e+02\n",
      "     2.0200e+02]\n",
      "   [ 1.3400e+02  1.3000e+02  1.3200e+02 ...  1.8600e+02  1.2300e+02\n",
      "     8.7000e+01]\n",
      "   ...\n",
      "   [ 1.6400e+02  1.1300e+02  2.2000e+01 ...  1.2700e+02  7.3000e+01\n",
      "     3.8000e+01]\n",
      "   [ 1.3600e+02  1.4400e+02  1.5700e+02 ...  1.8900e+02  1.5900e+02\n",
      "     1.3900e+02]\n",
      "   [ 1.1500e+02  1.5900e+02  2.3300e+02 ...  2.2700e+02  2.1200e+02\n",
      "     2.0100e+02]]\n",
      "\n",
      "  [[ 2.1600e+02  1.2300e+02  3.1000e+01 ...  1.8200e+02  1.7000e+01\n",
      "     7.8000e+01]\n",
      "   [ 6.0000e+01  9.6000e+01  7.8000e+01 ...  2.1200e+02  2.5100e+02\n",
      "     1.9700e+02]\n",
      "   [ 1.1000e+02  1.8400e+02  2.0100e+02 ...  3.4000e+01  1.4500e+02\n",
      "     4.4000e+01]\n",
      "   ...\n",
      "   [ 9.8000e+01  1.0000e+01  1.4600e+02 ...  1.4900e+02  2.4000e+01\n",
      "     6.2000e+01]\n",
      "   [ 8.8000e+01  2.5000e+02  2.2200e+02 ...  2.1400e+02  1.4100e+02\n",
      "     6.4375e+01]\n",
      "   [ 1.5000e+02  4.8000e+01  6.4000e+01 ...  1.8900e+02  4.4000e+01\n",
      "     5.1000e+01]]\n",
      "\n",
      "  [[ 8.3938e+01  5.5125e+01  2.6609e+01 ...  7.3438e+01  2.2266e+01\n",
      "     4.1188e+01]\n",
      "   [ 3.5594e+01  4.6750e+01  4.1188e+01 ...  8.2750e+01  9.4812e+01\n",
      "     7.8062e+01]\n",
      "   [ 1.9990e+03  7.4062e+01  7.9312e+01 ...  2.7547e+01  6.1938e+01\n",
      "     3.0641e+01]\n",
      "   ...\n",
      "   [ 4.7375e+01  2.0094e+01  6.2250e+01 ...  6.3188e+01  2.4438e+01\n",
      "     3.6219e+01]\n",
      "   [ 4.4281e+01  9.4500e+01  8.5812e+01 ...  8.3312e+01  6.0719e+01\n",
      "     4.4906e+01]\n",
      "   [ 6.3500e+01  3.1875e+01  3.6844e+01 ...  7.5562e+01  3.0641e+01\n",
      "     3.2812e+01]]]\n",
      "\n",
      "\n",
      " [[[ 6.4000e+01  1.1000e+02  1.8300e+02 ...  1.0600e+02  1.9000e+02\n",
      "     2.3500e+02]\n",
      "   [ 1.0500e+02  1.3100e+02  1.7300e+02 ...  7.2000e+01  1.5900e+02\n",
      "     2.0700e+02]\n",
      "   [ 1.6900e+02  1.6100e+02  1.4900e+02 ...  1.9000e+01 -6.3000e+01\n",
      "     1.5100e+02]\n",
      "   ...\n",
      "   [ 2.5500e+02  9.6000e+03  2.4000e+01 ...  1.7100e+02  1.8300e+02\n",
      "     1.8400e+02]\n",
      "   [ 2.1400e+02  1.8100e+02  1.1200e+02 ...  9.2000e+01  1.1500e+02\n",
      "     1.2800e+02]\n",
      "   [ 1.8600e+02  1.7900e+02  1.6200e+02 ...  4.4000e+01  7.7000e+01\n",
      "     9.8000e+01]]\n",
      "\n",
      "  [[ 7.2000e+01  1.1200e+02  4.9000e+01 ...  1.3300e+02  3.9000e+01\n",
      "     1.8200e+02]\n",
      "   [ 1.8900e+02  3.0000e+00  4.9000e+01 ...  2.5300e+02  1.7700e+02\n",
      "     6.0000e+00]\n",
      "   [ 1.6200e+02  1.8000e+02  2.1100e+02 ...  1.9900e+02  1.6200e+02\n",
      "     1.1100e+02]\n",
      "   ...\n",
      "   [ 3.2000e+01  1.9300e+02  7.7000e+01 ...  1.2900e+02  2.0400e+02\n",
      "     1.3100e+02]\n",
      "   [ 1.9600e+02  1.4600e+02  1.3700e+02 ...  4.9000e+01  7.8000e+01\n",
      "     4.9000e+01]\n",
      "   [ 3.3000e+01  2.2700e+02  1.9600e+02 ...  1.7900e+02  1.4600e+02\n",
      "     2.2700e+02]]\n",
      "\n",
      "  [[ 3.9312e+01  5.1719e+01  3.2188e+01 ...  5.8219e+01  2.9094e+01\n",
      "     7.3438e+01]\n",
      "   [ 7.5562e+01  1.7938e+01  3.2188e+01 ...  9.5438e+01  7.1875e+01\n",
      "     1.8859e+01]\n",
      "   [ 6.7250e+01  7.2812e+01  8.2438e+01 ...  7.8688e+01  6.7250e+01\n",
      "     5.1406e+01]\n",
      "   ...\n",
      "   [ 2.6922e+01  7.6812e+01  4.0875e+01 ...  5.7000e+01  8.0250e+01\n",
      "     5.7625e+01]\n",
      "   [ 7.7750e+01  6.2250e+01  5.9469e+01 ...  3.2188e+01  4.1188e+01\n",
      "     3.2188e+01]\n",
      "   [ 2.7234e+01  8.7375e+01  7.7750e+01 ...  7.2500e+01  6.2250e+01\n",
      "     8.7375e+01]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devanshubisht/anaconda3/envs/cs2109s/lib/python3.9/site-packages/numpy/core/_methods.py:212: RuntimeWarning: overflow encountered in reduce\n",
      "  arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def remove_outliers(images, threshold=3):\n",
    "    flattened_images = images.reshape(images.shape[0], -1)\n",
    "    print(flattened_images.shape)\n",
    "    z_scores = zscore(flattened_images, axis=None)\n",
    "    outliers_mask = np.abs(z_scores) > threshold\n",
    "\n",
    "    flattened_images_no_outliers = flattened_images.copy()\n",
    "    flattened_images_no_outliers[outliers_mask] = 0\n",
    "\n",
    "    images_no_outliers = flattened_images_no_outliers.reshape(images.shape)\n",
    "\n",
    "    return images_no_outliers\n",
    "\n",
    "# Assuming 'images' is your image dataset with shape (2620, 3, 16, 16)\n",
    "# Remove outliers\n",
    "images_no_outliers = remove_outliers(images)\n",
    "print(images_no_outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2620, 3, 16, 16)\n",
      "Number of NaN values along dimension 0: [[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]]\n",
      "(3, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "print(images_no_outliers.shape)\n",
    "# Count NaN values along each dimension\n",
    "nan_count_dim0 = np.sum(np.isnan(images_no_outliers), axis=0)\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of NaN values along dimension 0:\", nan_count_dim0)\n",
    "print(nan_count_dim0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Height: 0, Column: 4\n",
      "Index: 1, Height: 0, Column: 12\n",
      "Index: 2, Height: 0, Column: 13\n",
      "Index: 3, Height: 1, Column: 6\n",
      "Index: 4, Height: 0, Column: 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_indices_above_threshold(images, threshold=256):\n",
    "    indices_above_threshold = []\n",
    "\n",
    "    for idx, img in enumerate(images):\n",
    "        if np.any(img > threshold):\n",
    "            indices_above_threshold.append(idx)\n",
    "\n",
    "    return indices_above_threshold\n",
    "\n",
    "def display_info_for_indices(images, indices):\n",
    "    count = 0\n",
    "    for idx in indices:\n",
    "        img = images[idx]\n",
    "        positions = np.where(img > 256)\n",
    "        height = positions[1]\n",
    "        col = positions[2]\n",
    "        \n",
    "        \n",
    "\n",
    "        if len(height) == 0 or len(col) == 0:\n",
    "            # No values above threshold in this image\n",
    "            print(f\"Index: {idx}, No values above threshold\")\n",
    "        else:\n",
    "            print(f\"Index: {idx}, Height: {height[0]}, Column: {col[0]}\")\n",
    "        \n",
    "        count+=1\n",
    "        \n",
    "        if count == 5:\n",
    "            break\n",
    "        \n",
    "\n",
    "# Replace this with your actual dataset\n",
    "images = np.random.random((2620, 3, 16, 16)) * 300  # Example data with values above 256\n",
    "\n",
    "# Find indices where RGB values are greater than 256\n",
    "indices_with_values_above_256 = find_indices_above_threshold(images)\n",
    "\n",
    "# Display information for the identified indices\n",
    "display_info_for_indices(images, indices_with_values_above_256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2620, 3, 16, 16)\n",
      "(2624,)\n"
     ]
    }
   ],
   "source": [
    "print(images_interpolated.shape)\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4916043",
   "metadata": {},
   "source": [
    "### 4. Detection and Handling of Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ad3ab20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2.], dtype=float16), array([2392,  203,   25]))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data balancing\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Assuming you have images_interpolated and labels\n",
    "\n",
    "# Reshape the images to (N, -1) where N is the number of samples\n",
    "images_reshaped = images_interpolated.reshape(images_interpolated.shape[0], -1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_reshaped, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use RandomOverSampler to oversample the minority classes\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Reshape the images back to (N, 3, 16, 16)\n",
    "X_train_resampled = X_train_resampled.reshape(X_train_resampled.shape[0], 3, 16, 16)\n",
    "\n",
    "# Now you can use X_train_resampled and y_train_resampled for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = images_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Assuming labels 1 and 2 are minority classes\n",
    "minority_labels = [1, 2]\n",
    "\n",
    "# Find the number of instances of label 0\n",
    "num_instances_label_0 = np.sum(labels == 0)\n",
    "\n",
    "# Iterate over each minority class\n",
    "for minority_label in minority_labels:\n",
    "    # Find indices of samples belonging to the minority class\n",
    "    minority_indices = np.where(labels == minority_label)[0]\n",
    "\n",
    "    # Calculate the number of instances to add for augmentation\n",
    "    num_instances_to_add = num_instances_label_0 - len(minority_indices)\n",
    "\n",
    "    # Randomly sample from the minority class indices to match the count of label 0\n",
    "    sampled_minority_indices = np.random.choice(minority_indices, size=num_instances_to_add, replace=True)\n",
    "\n",
    "    # Apply your data augmentation to the samples at sampled_minority_indices\n",
    "    for idx in sampled_minority_indices:\n",
    "        # Assuming data is in the shape (C, H, W)\n",
    "        image_data = torch.tensor(images_test[idx])  # Convert to PyTorch tensor\n",
    "\n",
    "        # Apply transformations (you can customize these)\n",
    "        if np.random.rand() < 0.5:\n",
    "            # Random horizontal flip\n",
    "            image_data = torch.flip(image_data, dims=[2])\n",
    "        if np.random.rand() < 0.5:\n",
    "            # Random vertical flip\n",
    "            image_data = torch.flip(image_data, dims=[1])\n",
    "        if np.random.rand() < 0.5:\n",
    "            # Random rotation (clockwise)\n",
    "            angle = np.random.uniform(-30, 30)\n",
    "            image_data = torch.transpose(torch.flip(image_data, dims=[1]), 1, 2)  # Rotate 90 degrees clockwise\n",
    "\n",
    "        # Append the augmented data to the original dataset\n",
    "        images_test = np.concatenate([images_test, [image_data.numpy()]], axis=0)\n",
    "        labels = np.concatenate([labels, [minority_label]])\n",
    "\n",
    "# Now, images and labels contain the augmented dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7176, 3, 16, 16)\n",
      "(array([0, 1, 2]), array([14,  9,  5]))\n",
      "[[[[9.9219e-01 9.4141e-01 8.0371e-01 ... 9.4531e-01 3.1763e-01\n",
      "    0.0000e+00]\n",
      "   [9.4922e-01 8.6670e-01 6.9434e-01 ... 8.4717e-01 2.6660e-01\n",
      "    0.0000e+00]\n",
      "   [8.5107e-01 7.0996e-01 4.7852e-01 ... 6.8604e-01 2.0789e-01\n",
      "    0.0000e+00]\n",
      "   ...\n",
      "   [1.5686e-02 3.1372e-02 5.4901e-02 ... 7.1387e-01 7.9199e-01\n",
      "    8.1592e-01]\n",
      "   [1.9604e-01 3.6084e-01 6.3135e-01 ... 6.8604e-01 6.7822e-01\n",
      "    6.9189e-01]\n",
      "   [3.0200e-01 5.4883e-01 9.5703e-01 ... 6.5088e-01 6.0010e-01\n",
      "    5.7275e-01]]\n",
      "\n",
      "  [[7.9199e-01 4.9414e-01 9.0210e-02 ... 9.4922e-01 8.0762e-01\n",
      "    3.9209e-01]\n",
      "   [1.0000e+00 2.6270e-01 4.3530e-01 ... 4.0796e-01 7.7246e-01\n",
      "    3.5303e-01]\n",
      "   [9.9609e-01 3.8818e-01 7.9590e-01 ... 9.2920e-01 2.1179e-01\n",
      "    5.6055e-01]\n",
      "   ...\n",
      "   [4.5874e-01 9.0186e-01 3.1372e-02 ... 3.4912e-01 6.9434e-01\n",
      "    1.5686e-01]\n",
      "   [9.8438e-01 7.4121e-01 3.7646e-01 ... 2.3132e-01 4.1479e-01\n",
      "    4.8242e-01]\n",
      "   [6.4697e-01 6.9434e-01 0.0000e+00 ... 5.8838e-02 9.2529e-01\n",
      "    4.1968e-01]]\n",
      "\n",
      "  [[3.1226e-01 2.1985e-01 9.4604e-02 ... 3.6084e-01 3.1714e-01\n",
      "    1.8823e-01]\n",
      "   [1.1531e+01 1.4819e-01 2.0154e-01 ... 1.9312e-01 3.0615e-01\n",
      "    1.7615e-01]\n",
      "   [3.7549e-01 1.8701e-01 3.1348e-01 ... 3.5498e-01 1.3232e-01\n",
      "    2.4060e-01]\n",
      "   ...\n",
      "   [2.0898e-01 3.4644e-01 1.2758e+01 ... 1.7493e-01 2.8198e-01\n",
      "    1.1530e-01]\n",
      "   [3.7183e-01 2.9639e-01 1.8335e-01 ... 1.3831e-01 2.7686e-01\n",
      "    2.1619e-01]\n",
      "   [2.6709e-01 2.8198e-01 6.6650e-02 ... 8.4900e-02 3.5376e-01\n",
      "    1.9666e-01]]]\n",
      "\n",
      "\n",
      " [[[9.2920e-01 5.8057e-01 1.1765e-02 ... 6.4307e-01 1.9604e-01\n",
      "    0.0000e+00]\n",
      "   [7.3730e-01 6.0010e-01 3.6865e-01 ... 5.3711e-01 2.2351e-01\n",
      "    6.6650e-02]\n",
      "   [3.9990e-01 6.1182e-01 9.4141e-01 ... 3.7256e-01 3.0591e-01\n",
      "    3.5375e+01]\n",
      "   ...\n",
      "   [9.4141e-01 0.0000e+00 8.6304e-02 ... 1.5686e-01 4.5483e-01\n",
      "    6.1963e-01]\n",
      "   [6.3916e-01 5.4883e-01 3.9990e-01 ... 2.7051e-01 2.3535e-01\n",
      "    2.6422e+01]\n",
      "   [4.5874e-01 4.9805e-01 5.7666e-01 ... 3.3716e-01 1.0590e-01\n",
      "    0.0000e+00]]\n",
      "\n",
      "  [[4.9414e-01 5.6494e-01 6.3135e-01 ... 2.1570e-01 3.6475e-01\n",
      "    7.2949e-01]\n",
      "   [4.3140e-01 4.7461e-01 7.5293e-01 ... 4.7852e-01 8.1982e-01\n",
      "    0.0000e+00]\n",
      "   [8.7061e-01 7.8430e-02 7.6855e-01 ... 4.0381e-01 4.8633e-01\n",
      "    4.5093e-01]\n",
      "   ...\n",
      "   [9.8047e-01 4.1577e-01 8.6304e-02 ... 7.8430e-02 6.7041e-01\n",
      "    3.4106e-01]\n",
      "   [2.6270e-01 8.9404e-01 7.2559e-01 ... 7.0215e-01 9.7266e-01\n",
      "    4.2749e-01]\n",
      "   [1.6077e-01 0.0000e+00 3.4912e-01 ... 1.3330e-01 7.8027e-01\n",
      "    2.0789e-01]]\n",
      "\n",
      "  [[2.1985e-01 2.4170e-01 2.6245e-01 ... 1.3354e-01 1.7981e-01\n",
      "    2.9297e-01]\n",
      "   [2.0032e-01 2.1375e-01 3.0005e-01 ... 2.1497e-01 3.2080e-01\n",
      "    6.6650e-02]\n",
      "   [3.3643e-01 9.1003e-02 3.0493e-01 ... 1.9189e-01 2.1741e-01\n",
      "    2.0654e-01]\n",
      "   ...\n",
      "   [3.7061e-01 1.9556e-01 9.3384e-02 ... 9.1003e-02 2.7441e-01\n",
      "    1.7249e-01]\n",
      "   [1.4819e-01 3.4399e-01 2.9175e-01 ... 2.8442e-01 3.6816e-01\n",
      "    1.9910e-01]\n",
      "   [1.1646e-01 6.6650e-02 1.7493e-01 ... 1.0803e-01 3.0859e-01\n",
      "    1.3110e-01]]]\n",
      "\n",
      "\n",
      " [[[9.2920e-01 8.1592e-01 5.9229e-01 ... 8.5498e-01 2.6270e-01\n",
      "    0.0000e+00]\n",
      "   [9.4141e-01 7.9980e-01 5.2539e-01 ... 7.5684e-01 2.9810e-01\n",
      "    7.4524e-02]\n",
      "   [9.2139e-01 7.2949e-01 3.8818e-01 ... 5.7275e-01 3.6084e-01\n",
      "    2.4316e-01]\n",
      "   ...\n",
      "   [1.0000e+00 7.1387e-01 1.4124e-01 ... 3.7646e-01 5.5273e-01\n",
      "    6.3916e-01]\n",
      "   [1.0000e+00 7.6465e-01 3.2935e-01 ... 6.6650e-01 5.5273e-01\n",
      "    4.7070e-01]\n",
      "   [9.9609e-01 7.8027e-01 4.3530e-01 ... 8.2373e-01 5.4102e-01\n",
      "    3.6475e-01]]\n",
      "\n",
      "  [[3.8037e-01 4.7058e-02 1.8042e-01 ... 3.7256e-01 4.3530e-01\n",
      "    1.8433e-01]\n",
      "   [6.2744e-02 6.7822e-01 3.0981e-01 ... 1.9604e-01 8.9014e-01\n",
      "    4.9023e-01]\n",
      "   [6.3135e-01 5.3711e-01 2.7451e-02 ... 6.4697e-01 0.0000e+00\n",
      "    7.0618e-02]\n",
      "   ...\n",
      "   [4.3140e-01 1.9214e-01 4.7461e-01 ... 4.9023e-01 3.0981e-01\n",
      "    8.1152e-01]\n",
      "   [8.5889e-01 5.1367e-01 5.5664e-01 ... 3.6475e-01 1.6858e-01\n",
      "    3.0981e-01]\n",
      "   [6.4697e-01 4.6265e-01 1.5686e-01 ... 4.7070e-01 1.6858e-01\n",
      "    8.3936e-01]]\n",
      "\n",
      "  [[1.8457e-01 8.1238e-02 1.2262e-01 ... 1.8213e-01 2.0154e-01\n",
      "    1.2378e-01]\n",
      "   [8.6121e-02 2.7686e-01 1.6272e-01 ... 1.2744e-01 3.4253e-01\n",
      "    2.1863e-01]\n",
      "   [2.6245e-01 2.3315e-01 7.5195e-02 ... 2.6709e-01 6.6650e-02\n",
      "    8.8562e-02]\n",
      "   ...\n",
      "   [2.0032e-01 1.2622e-01 2.1375e-01 ... 2.1863e-01 1.6272e-01\n",
      "    3.1836e-01]\n",
      "   [3.3276e-01 2.2595e-01 2.3938e-01 ... 3.6816e-01 1.1896e-01\n",
      "    1.6272e-01]\n",
      "   [2.6709e-01 2.1021e-01 1.1530e-01 ... 2.1252e-01 1.1896e-01\n",
      "    3.2666e-01]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[8.7451e-01 7.8809e-01 6.4307e-01 ... 4.3921e-01 6.1572e-01\n",
      "    7.2168e-01]\n",
      "   [8.6670e-01 8.2373e-01 7.2949e-01 ... 2.8638e-01 4.0796e-01\n",
      "    4.8242e-01]\n",
      "   [8.4326e-01 8.7061e-01 8.7061e-01 ... 1.9608e-02 5.8838e-02\n",
      "    9.0210e-02]\n",
      "   ...\n",
      "   [6.2744e-02 7.0618e-02 1.0590e-01 ... 0.0000e+00 6.6260e-01\n",
      "    8.1982e-01]\n",
      "   [1.3330e-01 2.9810e-01 5.8838e-01 ... 4.9023e-01 3.4521e-01\n",
      "    0.0000e+00]\n",
      "   [1.8433e-01 4.4312e-01 8.7451e-01 ... 5.2148e-01 1.6858e-01\n",
      "    0.0000e+00]]\n",
      "\n",
      "  [[5.6055e-01 7.7637e-01 7.8027e-01 ... 2.7051e-01 3.8428e-01\n",
      "    8.5498e-01]\n",
      "   [9.2920e-01 4.0796e-01 4.9414e-01 ... 6.2744e-01 6.7432e-01\n",
      "    3.3325e-01]\n",
      "   [3.9215e-02 8.6670e-01 4.5093e-01 ... 6.4307e-01 2.7832e-01\n",
      "    7.5293e-01]\n",
      "   ...\n",
      "   [4.5483e-01 9.9609e-01 1.5686e-02 ... 8.0762e-01 3.8818e-01\n",
      "    4.0796e-01]\n",
      "   [5.6885e-01 7.6465e-01 5.1758e-01 ... 9.3311e-01 2.2742e-01\n",
      "    1.4905e-01]\n",
      "   [6.1572e-01 5.5273e-01 8.3545e-01 ... 9.8828e-01 1.8433e-01\n",
      "    2.9028e-01]]\n",
      "\n",
      "  [[2.4060e-01 3.0737e-01 3.0859e-01 ... 1.5051e-01 1.8579e-01\n",
      "    3.3154e-01]\n",
      "   [3.5498e-01 1.9312e-01 2.1985e-01 ... 2.6123e-01 2.7563e-01\n",
      "    1.6992e-01]\n",
      "   [7.8796e-02 3.3521e-01 2.0654e-01 ... 2.6587e-01 1.5295e-01\n",
      "    3.0005e-01]\n",
      "   ...\n",
      "   [2.0776e-01 3.7549e-01 7.1533e-02 ... 3.1714e-01 1.8701e-01\n",
      "    1.9312e-01]\n",
      "   [2.4292e-01 3.0371e-01 2.2705e-01 ... 3.5596e-01 1.3708e-01\n",
      "    1.1285e-01]\n",
      "   [2.5757e-01 2.3816e-01 3.2544e-01 ... 3.7305e-01 1.2378e-01\n",
      "    1.5662e-01]]]\n",
      "\n",
      "\n",
      " [[[8.5498e-01 7.9590e-01 6.6260e-01 ... 7.9199e-01 7.8027e-01\n",
      "    7.6855e-01]\n",
      "   [6.7041e-01 6.1963e-01 5.1367e-01 ... 8.2764e-01 8.1982e-01\n",
      "    8.0371e-01]\n",
      "   [3.6475e-01 3.2153e-01 2.4707e-01 ... 8.4717e-01 8.7451e-01\n",
      "    8.7451e-01]\n",
      "   ...\n",
      "   [9.2920e-01 7.4121e-01 3.9209e-01 ... 2.7451e-02 2.2351e-01\n",
      "    3.3325e-01]\n",
      "   [9.8438e-01 8.4326e-01 5.7666e-01 ... 1.7261e-01 3.9209e-01\n",
      "    5.0977e-01]\n",
      "   [1.0000e+00 9.0576e-01 6.8604e-01 ... 2.5879e-01 4.8633e-01\n",
      "    6.0791e-01]]\n",
      "\n",
      "  [[2.1960e-01 9.4141e-01 6.5088e-01 ... 7.2168e-01 5.4901e-02\n",
      "    6.9434e-01]\n",
      "   [4.5093e-01 1.2549e-01 2.2742e-01 ... 7.1387e-01 3.1372e-02\n",
      "    0.0000e+00]\n",
      "   [6.8604e-01 3.5303e-01 6.5479e-01 ... 2.3132e-01 4.0381e-01\n",
      "    2.0398e-01]\n",
      "   ...\n",
      "   [9.4922e-01 9.1748e-01 5.4901e-02 ... 5.5664e-01 1.8823e-01\n",
      "    0.0000e+00]\n",
      "   [1.8823e-01 4.7461e-01 9.0186e-01 ... 3.1763e-01 9.0576e-01\n",
      "    6.9824e-01]\n",
      "   [9.1748e-01 4.3921e-01 9.0967e-01 ... 2.1179e-01 9.5312e-01\n",
      "    2.1179e-01]]\n",
      "\n",
      "  [[1.3477e-01 3.5840e-01 2.6831e-01 ... 2.9053e-01 8.3679e-02\n",
      "    2.8198e-01]\n",
      "   [2.0654e-01 1.0559e-01 1.3708e-01 ... 2.8809e-01 7.6416e-02\n",
      "    1.8701e-01]\n",
      "   [2.7930e-01 1.7615e-01 2.6953e-01 ... 1.3831e-01 1.9189e-01\n",
      "    1.2988e-01]\n",
      "   ...\n",
      "   [3.6084e-01 3.5132e-01 8.3679e-02 ... 2.3938e-01 1.2500e-01\n",
      "    8.2458e-02]\n",
      "   [1.2500e-01 2.1375e-01 3.4644e-01 ... 1.6516e-01 3.4766e-01\n",
      "    2.8320e-01]\n",
      "   [3.5132e-01 2.0276e-01 3.4888e-01 ... 1.3232e-01 3.6206e-01\n",
      "    1.3232e-01]]]\n",
      "\n",
      "\n",
      " [[[1.0000e+00 9.9219e-01 9.1357e-01 ... 9.1748e-01 5.7275e-01\n",
      "    3.6865e-01]\n",
      "   [7.6465e-01 8.4326e-01 9.4531e-01 ... 9.1748e-01 5.5273e-01\n",
      "    3.3716e-01]\n",
      "   [2.3926e-01 4.9805e-01 0.0000e+00 ... 9.0186e-01 5.0586e-01\n",
      "    2.8247e-01]\n",
      "   ...\n",
      "   [6.4307e-01 4.3530e-01 7.0618e-02 ... 3.5693e-01 4.2358e-01\n",
      "    4.5093e-01]\n",
      "   [4.2358e-01 4.3140e-01 4.1968e-01 ... 6.2354e-01 7.6855e-01\n",
      "    8.4326e-01]\n",
      "   [2.8247e-01 4.2358e-01 6.3135e-01 ... 7.8027e-01 9.3701e-01\n",
      "    1.0000e+00]]\n",
      "\n",
      "  [[2.0398e-01 8.8232e-01 2.5098e-01 ... 2.7051e-01 1.0590e-01\n",
      "    2.0789e-01]\n",
      "   [6.6650e-02 8.0371e-01 5.3711e-01 ... 3.9209e-01 1.1765e-02\n",
      "    5.3320e-01]\n",
      "   [2.6660e-01 6.4307e-01 2.6660e-01 ... 2.7832e-01 3.1372e-02\n",
      "    6.3525e-01]\n",
      "   ...\n",
      "   [4.5337e-01 5.7666e-01 6.3525e-01 ... 3.4106e-01 3.1372e-02\n",
      "    3.6475e-01]\n",
      "   [8.2336e-02 6.0400e-01 4.7058e-02 ... 2.3132e-01 3.9209e-01\n",
      "    2.4084e-01]\n",
      "   [3.4912e-01 8.0371e-01 8.1152e-01 ... 8.3154e-01 5.8838e-02\n",
      "    3.5693e-01]]\n",
      "\n",
      "  [[1.2988e-01 3.4009e-01 1.4453e-01 ... 1.5051e-01 9.9487e-02\n",
      "    1.3110e-01]\n",
      "   [8.7341e-02 3.1592e-01 2.3315e-01 ... 1.8823e-01 7.0374e-02\n",
      "    2.3193e-01]\n",
      "   [1.4941e-01 2.6587e-01 1.4941e-01 ... 1.5295e-01 7.6416e-02\n",
      "    2.6367e-01]\n",
      "   ...\n",
      "   [2.9883e-01 2.4536e-01 2.6367e-01 ... 1.7249e-01 1.9922e+01\n",
      "    1.7981e-01]\n",
      "   [9.2224e-02 2.5391e-01 8.1238e-02 ... 1.3831e-01 1.8823e-01\n",
      "    1.2744e-01]\n",
      "   [1.7493e-01 3.1592e-01 3.1836e-01 ... 3.2446e-01 8.4900e-02\n",
      "    1.7737e-01]]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(images_test.shape)\n",
    "print(np.unique(labels, return_counts=True))\n",
    "images_test_copy = images_test\n",
    "label_copy =labels\n",
    "print(images_test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2 Score: 0.9321839232494916\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_test_copy, label_copy, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create a PyTorch DataLoader for the training set\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create a PyTorch DataLoader for the test set\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the CNN model\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes, dropout_rate=0.3):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        # self.bn1 = nn.BatchNorm2d(32)  # BatchNorm after the first convolution\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout2d(p=dropout_rate)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        # self.bn2 = nn.BatchNorm2d(64)  # BatchNorm after the second convolution\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout2d(p=dropout_rate)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc = nn.Linear(64 * 4 * 4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.dropout1(self.act1(self.conv1(x))))\n",
    "        x = self.pool2(self.dropout2(self.act2(self.conv2(x))))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor for the fully connected layer\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "num_classes = 3  # Change this based on your dataset\n",
    "model = SimpleCNN(num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Testing the model\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate F2 score\n",
    "f2_score = fbeta_score(all_true_labels, all_predictions, beta=2, average='macro')\n",
    "\n",
    "print(f\"F2 Score: {f2_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class Model:  \n",
    "    \"\"\"\n",
    "    This class represents an AI model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor for Model class.\n",
    "  \n",
    "        Parameters\n",
    "        ----------\n",
    "        self : object\n",
    "            The instance of the object passed by Python.\n",
    "        \"\"\"\n",
    "        # TODO: Replace the following code with your own initialization code.\n",
    "        self.model = None\n",
    "\n",
    "    def nearest_neighbor_interpolation(self, image):\n",
    "        c, h, w = image.shape\n",
    "\n",
    "        nan_mask = np.isnan(image)\n",
    "        # Find indices of NaN values\n",
    "        nan_indices = np.where(nan_mask)\n",
    "\n",
    "        # Iterate through each NaN pixel and replace it with the mean of its neighbors\n",
    "        for idx in range(len(nan_indices[0])):\n",
    "            y, x = nan_indices[1][idx], nan_indices[2][idx]\n",
    "\n",
    "            # Extract the 8 neighboring pixels for each channel without wrapping around\n",
    "            for channel in range(c):\n",
    "                valid_neighbors = [\n",
    "                    image[channel, y2, x2]\n",
    "                    for y2 in range(max(0, y - 1), min(h, y + 2))\n",
    "                    for x2 in range(max(0, x - 1), min(w, x + 2))\n",
    "                    if (y2, x2) != (y, x)\n",
    "                ]\n",
    "\n",
    "                # Calculate the mean of the valid neighbors and replace the NaN value for each channel\n",
    "                image[channel, y, x] = np.nanmean(valid_neighbors)\n",
    "\n",
    "        return image\n",
    "\n",
    "    images_interpolated1 = np.array([interpolate_nan_pixels(img) for img in image_test])\n",
    "\n",
    "    def oversample(self, images, labels):\n",
    "        minority_labels = [1, 2]\n",
    "        # Find the number of instances of label 0\n",
    "        num_instances_label_0 = np.sum(labels == 0)\n",
    "        for minority_label in minority_labels:\n",
    "            # Find indices of samples belonging to the minority class\n",
    "            minority_indices = np.where(labels == minority_label)[0]\n",
    "            # Calculate the number of instances to add for augmentation\n",
    "            num_instances_to_add = num_instances_label_0 - len(minority_indices)\n",
    "            # Randomly sample from the minority class indices to match the count of label 0\n",
    "            sampled_minority_indices = np.random.choice(minority_indices, size=num_instances_to_add, replace=True)\n",
    "            # Apply your data augmentation to the samples at sampled_minority_indices\n",
    "            for idx in sampled_minority_indices:\n",
    "                # Assuming data is in the shape (C, H, W)\n",
    "                image_data = torch.tensor(images[idx])  # Convert to PyTorch tensor\n",
    "                # Apply transformations (you can customize these)\n",
    "                if np.random.rand() < 0.2:\n",
    "                    # Random horizontal flip\n",
    "                    image_data = torch.flip(image_data, dims=[2])\n",
    "                if np.random.rand() < 0.2:\n",
    "                    # Random rotation (clockwise)\n",
    "                    angle = np.random.uniform(-30, 30)\n",
    "                    image_data = torch.transpose(torch.flip(image_data, dims=[1]), 1, 2)  # Rotate 90 degrees clockwis\n",
    "\n",
    "                # Append the augmented data to the original dataset\n",
    "                images = np.concatenate([images, [image_data.numpy()]], axis=0)\n",
    "                labels = np.concatenate([labels, [minority_label]])\n",
    "        \n",
    "        return images, labels\n",
    "    \n",
    "    def preprocess(self, X, y= None):\n",
    "        if y is not None:\n",
    "            # Remove NaN labels\n",
    "            nan_mask = np.isnan(y)\n",
    "            labels = y[~nan_mask]\n",
    "            images = X[~nan_mask]\n",
    "\n",
    "            images[images < 0] = 0  # Set negative pixel values to 0\n",
    "            images[images > 255] = 255  # Set pixel values > 1 to 1\n",
    "\n",
    "            # Interpolate missing values\n",
    "            images = np.array([self.nearest_neighbor_interpolation(img) for img in images])\n",
    "\n",
    "            # Standardize values\n",
    "            images = images / 255.0\n",
    "\n",
    "            # Oversample to handle imbalance through augmentation\n",
    "            images, labels = self.oversample(images, labels)\n",
    "\n",
    "            return (images, labels)\n",
    "        \n",
    "        else:\n",
    "            print(\"Preprocessing test data\")\n",
    "            X[X < 0] = 0  # Set negative pixel values to 0\n",
    "            X[X > 255] = 255\n",
    "            # Standardize values\n",
    "            X = X/255.0\n",
    "            images = np.array([self.nearest_neighbor_interpolation(img) for img in X])\n",
    "            return (images)\n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        images, labels = self.preprocess(X, y)\n",
    "        nan_count_dim0 = np.sum(np.isnan(images), axis=0)\n",
    "\n",
    "        images_train = torch.tensor(images, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "        train_dataset = TensorDataset(images_train, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "        class CNN(nn.Module):\n",
    "            def __init__(self, num_classes, dropout_rate=0.3):\n",
    "                super(CNN, self).__init__()\n",
    "                self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "                self.bn1 = nn.BatchNorm2d(32)  # BatchNorm after the first convolution\n",
    "                self.act1 = nn.ReLU()\n",
    "                self.dropout1 = nn.Dropout2d(p=dropout_rate)\n",
    "                self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "                self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "                self.bn2 = nn.BatchNorm2d(64)  # BatchNorm after the second convolution\n",
    "                self.act2 = nn.ReLU()\n",
    "                self.dropout2 = nn.Dropout2d(p=dropout_rate)\n",
    "                self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "                self.fc = nn.Linear(64 * 4 * 4, num_classes)\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = self.pool1(self.dropout1(self.act1(self.bn1(self.conv1(x)))))\n",
    "                x = self.pool2(self.dropout2(self.act2(self.bn2(self.conv2(x)))))\n",
    "                x = x.view(x.size(0), -1)  # Flatten the tensor for the fully connected layer\n",
    "                x = self.fc(x)\n",
    "                return x\n",
    "        \n",
    "                train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "        # class CNN(nn.Module):\n",
    "        #     def __init__(self, num_classes, dropout_rate=0.2):\n",
    "        #         super(CNN, self).__init__()\n",
    "        #         self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        #         self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        #         self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "                \n",
    "        #         self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        #         self.act = nn.LeakyReLU(negative_slope=0.02)\n",
    "        #         self.dropout = nn.Dropout2d(p=dropout_rate)\n",
    "        #         self.flatten = nn.Flatten()\n",
    "\n",
    "        #         self.fc1 = nn.Linear(128 * 2 * 2, num_classes)  # New linear layer\n",
    "        #         # self.relu = nn.ReLU()  # ReLU activation\n",
    "        #         # self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "        #     def forward(self, x):\n",
    "        #         x = self.dropout(self.pool(self.act(self.conv1(x))))\n",
    "        #         x = self.dropout(self.pool(self.act(self.conv2(x))))\n",
    "        #         x = self.dropout(self.pool(self.act(self.conv3(x))))\n",
    "        #         x = self.flatten(x)\n",
    "\n",
    "        #         # Apply the new linear layer with ReLU activation\n",
    "        #         x = self.fc1(x)\n",
    "        #         return x\n",
    "\n",
    "\n",
    "        # Instantiate the model\n",
    "        num_classes = 3  # Change this based on your dataset\n",
    "        self.model = CNN(num_classes)\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.RMSprop(self.model.parameters(), lr=0.001)\n",
    "\n",
    "        # Training the model\n",
    "        num_epochs = 50\n",
    "        for _ in range(num_epochs):\n",
    "            self.model.train()\n",
    "            running_loss = 0.0\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Use the trained model to make predictions.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, channel, height, width)\n",
    "            Input data.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        ndarray of shape (n_samples,)\n",
    "        Predicted target values per element in X.\n",
    "           \n",
    "        \"\"\"\n",
    "        # Preprocess the test data\n",
    "        X = self.preprocess(X)\n",
    "        \n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "        # Make predictions using the trained neural network\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X_tensor)\n",
    "\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "\n",
    "        # Convert PyTorch tensor to numpy array\n",
    "        return predicted_labels.numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2552a795",
   "metadata": {},
   "source": [
    "### 5. Understanding Relationship Between Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ddbbcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "757fb315",
   "metadata": {},
   "source": [
    "### 6. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f82e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a7eebcf",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3e3383",
   "metadata": {},
   "source": [
    "### 7. General Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19174365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb3aa527",
   "metadata": {},
   "source": [
    "### 8. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85808bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4921e8ca",
   "metadata": {},
   "source": [
    "### 9. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcde626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa676c3f",
   "metadata": {},
   "source": [
    "## Modeling & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589b37e4",
   "metadata": {},
   "source": [
    "### 10. Creating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dffd7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "495bf3c0",
   "metadata": {},
   "source": [
    "### 11. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9245ab47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8aa31404",
   "metadata": {},
   "source": [
    "### 12. Hyperparameters Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81addd51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
